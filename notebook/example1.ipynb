{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from data_preprocessing  import preprocessing\n",
    "pre=preprocessing()\n",
    "input_features=pre.input_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rajes\\\\wafer_detection\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\rajes\\\\wafer_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from data_preprocessing  import preprocessing\n",
    "pre=preprocessing()\n",
    "input_features=pre.input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wcss=[]\n",
    "for i in range(1,15):\n",
    "    kmean=KMeans(n_clusters=i,init='k-means++',random_state=30)\n",
    "    kmean.fit(input_features)\n",
    "    wcss.append(kmean.inertia_)\n",
    "plt.plot(range(1,15),wcss)\n",
    "plt.xlabel(\"no.of centriods\")\n",
    "plt.ylabel(\"wcss\")\n",
    "plt.savefig('Elbowplot.png')     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn = KneeLocator(range(1, 15), wcss, curve='convex', direction='decreasing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn.knee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>clusters</th>\n",
       "      <th>output_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  405 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0   3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1   2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2   2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3   2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4   3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "\n",
       "   Sensor-10  Sensor-11  Sensor-12  ...  Sensor-581  Sensor-583  Sensor-584  \\\n",
       "0     0.0089     0.0052     0.9655  ...    0.009000      0.5016      0.0152   \n",
       "1     0.0119    -0.0082     0.9572  ...    0.008100      0.4953      0.0105   \n",
       "2    -0.0143     0.0017     0.9702  ...    0.007333      0.4958      0.0111   \n",
       "3    -0.0534    -0.0284     0.9708  ...    0.004733      0.4962      0.0086   \n",
       "4    -0.0078    -0.0005     0.9680  ...    0.005867      0.4983      0.0159   \n",
       "\n",
       "   Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  clusters  \\\n",
       "0      0.0040      3.0319      0.0465      0.0299      0.0090         0   \n",
       "1      0.0037      2.1266     -0.0012      0.0252      0.0081         0   \n",
       "2      0.0033      2.2296     -0.0012      0.0252      0.0081         3   \n",
       "3      0.0024      1.7297     -0.0012      0.0252      0.0081         0   \n",
       "4      0.0041      3.1927     -0.0012      0.0252      0.0081         1   \n",
       "\n",
       "   output_feature  \n",
       "0            -1.0  \n",
       "1            -1.0  \n",
       "2            -1.0  \n",
       "3            -1.0  \n",
       "4            -1.0  \n",
       "\n",
       "[5 rows x 405 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot() missing 1 required positional argument: 'data_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23792\\3659119704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'scatter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: plot() missing 1 required positional argument: 'data_frame'"
     ]
    }
   ],
   "source": [
    "plotly.plot(x=input_features.iloc[:,1],y=input_features.iloc[:,-2],kind='scatter'===)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function plot in module matplotlib.pyplot:\n",
      "\n",
      "plot(*args, scalex=True, scaley=True, data=None, **kwargs)\n",
      "    Plot y versus x as lines and/or markers.\n",
      "    \n",
      "    Call signatures::\n",
      "    \n",
      "        plot([x], y, [fmt], *, data=None, **kwargs)\n",
      "        plot([x], y, [fmt], [x2], y2, [fmt2], ..., **kwargs)\n",
      "    \n",
      "    The coordinates of the points or line nodes are given by *x*, *y*.\n",
      "    \n",
      "    The optional parameter *fmt* is a convenient way for defining basic\n",
      "    formatting like color, marker and linestyle. It's a shortcut string\n",
      "    notation described in the *Notes* section below.\n",
      "    \n",
      "    >>> plot(x, y)        # plot x and y using default line style and color\n",
      "    >>> plot(x, y, 'bo')  # plot x and y using blue circle markers\n",
      "    >>> plot(y)           # plot y using x as index array 0..N-1\n",
      "    >>> plot(y, 'r+')     # ditto, but with red plusses\n",
      "    \n",
      "    You can use `.Line2D` properties as keyword arguments for more\n",
      "    control on the appearance. Line properties and *fmt* can be mixed.\n",
      "    The following two calls yield identical results:\n",
      "    \n",
      "    >>> plot(x, y, 'go--', linewidth=2, markersize=12)\n",
      "    >>> plot(x, y, color='green', marker='o', linestyle='dashed',\n",
      "    ...      linewidth=2, markersize=12)\n",
      "    \n",
      "    When conflicting with *fmt*, keyword arguments take precedence.\n",
      "    \n",
      "    \n",
      "    **Plotting labelled data**\n",
      "    \n",
      "    There's a convenient way for plotting objects with labelled data (i.e.\n",
      "    data that can be accessed by index ``obj['y']``). Instead of giving\n",
      "    the data in *x* and *y*, you can provide the object in the *data*\n",
      "    parameter and just give the labels for *x* and *y*::\n",
      "    \n",
      "    >>> plot('xlabel', 'ylabel', data=obj)\n",
      "    \n",
      "    All indexable objects are supported. This could e.g. be a `dict`, a\n",
      "    `pandas.DataFrame` or a structured numpy array.\n",
      "    \n",
      "    \n",
      "    **Plotting multiple sets of data**\n",
      "    \n",
      "    There are various ways to plot multiple sets of data.\n",
      "    \n",
      "    - The most straight forward way is just to call `plot` multiple times.\n",
      "      Example:\n",
      "    \n",
      "      >>> plot(x1, y1, 'bo')\n",
      "      >>> plot(x2, y2, 'go')\n",
      "    \n",
      "    - If *x* and/or *y* are 2D arrays a separate data set will be drawn\n",
      "      for every column. If both *x* and *y* are 2D, they must have the\n",
      "      same shape. If only one of them is 2D with shape (N, m) the other\n",
      "      must have length N and will be used for every data set m.\n",
      "    \n",
      "      Example:\n",
      "    \n",
      "      >>> x = [1, 2, 3]\n",
      "      >>> y = np.array([[1, 2], [3, 4], [5, 6]])\n",
      "      >>> plot(x, y)\n",
      "    \n",
      "      is equivalent to:\n",
      "    \n",
      "      >>> for col in range(y.shape[1]):\n",
      "      ...     plot(x, y[:, col])\n",
      "    \n",
      "    - The third way is to specify multiple sets of *[x]*, *y*, *[fmt]*\n",
      "      groups::\n",
      "    \n",
      "      >>> plot(x1, y1, 'g^', x2, y2, 'g-')\n",
      "    \n",
      "      In this case, any additional keyword argument applies to all\n",
      "      datasets. Also this syntax cannot be combined with the *data*\n",
      "      parameter.\n",
      "    \n",
      "    By default, each line is assigned a different style specified by a\n",
      "    'style cycle'. The *fmt* and line property parameters are only\n",
      "    necessary if you want explicit deviations from these defaults.\n",
      "    Alternatively, you can also change the style cycle using\n",
      "    :rc:`axes.prop_cycle`.\n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    x, y : array-like or scalar\n",
      "        The horizontal / vertical coordinates of the data points.\n",
      "        *x* values are optional and default to ``range(len(y))``.\n",
      "    \n",
      "        Commonly, these parameters are 1D arrays.\n",
      "    \n",
      "        They can also be scalars, or two-dimensional (in that case, the\n",
      "        columns represent separate data sets).\n",
      "    \n",
      "        These arguments cannot be passed as keywords.\n",
      "    \n",
      "    fmt : str, optional\n",
      "        A format string, e.g. 'ro' for red circles. See the *Notes*\n",
      "        section for a full description of the format strings.\n",
      "    \n",
      "        Format strings are just an abbreviation for quickly setting\n",
      "        basic line properties. All of these and more can also be\n",
      "        controlled by keyword arguments.\n",
      "    \n",
      "        This argument cannot be passed as keyword.\n",
      "    \n",
      "    data : indexable object, optional\n",
      "        An object with labelled data. If given, provide the label names to\n",
      "        plot in *x* and *y*.\n",
      "    \n",
      "        .. note::\n",
      "            Technically there's a slight ambiguity in calls where the\n",
      "            second label is a valid *fmt*. ``plot('n', 'o', data=obj)``\n",
      "            could be ``plt(x, y)`` or ``plt(y, fmt)``. In such cases,\n",
      "            the former interpretation is chosen, but a warning is issued.\n",
      "            You may suppress the warning by adding an empty format string\n",
      "            ``plot('n', 'o', '', data=obj)``.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    list of `.Line2D`\n",
      "        A list of lines representing the plotted data.\n",
      "    \n",
      "    Other Parameters\n",
      "    ----------------\n",
      "    scalex, scaley : bool, default: True\n",
      "        These parameters determine if the view limits are adapted to the\n",
      "        data limits. The values are passed on to `autoscale_view`.\n",
      "    \n",
      "    **kwargs : `.Line2D` properties, optional\n",
      "        *kwargs* are used to specify properties like a line label (for\n",
      "        auto legends), linewidth, antialiasing, marker face color.\n",
      "        Example::\n",
      "    \n",
      "        >>> plot([1, 2, 3], [1, 2, 3], 'go-', label='line 1', linewidth=2)\n",
      "        >>> plot([1, 2, 3], [1, 4, 9], 'rs', label='line 2')\n",
      "    \n",
      "        If you specify multiple lines with one plot call, the kwargs apply\n",
      "        to all those lines. In case the label object is iterable, each\n",
      "        element is used as labels for each set of data.\n",
      "    \n",
      "        Here is a list of available `.Line2D` properties:\n",
      "    \n",
      "        Properties:\n",
      "        agg_filter: a filter function, which takes a (m, n, 3) float array and a dpi value, and returns a (m, n, 3) array and two offsets from the bottom left corner of the image\n",
      "        alpha: scalar or None\n",
      "        animated: bool\n",
      "        antialiased or aa: bool\n",
      "        clip_box: `.Bbox`\n",
      "        clip_on: bool\n",
      "        clip_path: Patch or (Path, Transform) or None\n",
      "        color or c: color\n",
      "        dash_capstyle: `.CapStyle` or {'butt', 'projecting', 'round'}\n",
      "        dash_joinstyle: `.JoinStyle` or {'miter', 'round', 'bevel'}\n",
      "        dashes: sequence of floats (on/off ink in points) or (None, None)\n",
      "        data: (2, N) array or two 1D arrays\n",
      "        drawstyle or ds: {'default', 'steps', 'steps-pre', 'steps-mid', 'steps-post'}, default: 'default'\n",
      "        figure: `.Figure`\n",
      "        fillstyle: {'full', 'left', 'right', 'bottom', 'top', 'none'}\n",
      "        gid: str\n",
      "        in_layout: bool\n",
      "        label: object\n",
      "        linestyle or ls: {'-', '--', '-.', ':', '', (offset, on-off-seq), ...}\n",
      "        linewidth or lw: float\n",
      "        marker: marker style string, `~.path.Path` or `~.markers.MarkerStyle`\n",
      "        markeredgecolor or mec: color\n",
      "        markeredgewidth or mew: float\n",
      "        markerfacecolor or mfc: color\n",
      "        markerfacecoloralt or mfcalt: color\n",
      "        markersize or ms: float\n",
      "        markevery: None or int or (int, int) or slice or list[int] or float or (float, float) or list[bool]\n",
      "        path_effects: `.AbstractPathEffect`\n",
      "        picker: float or callable[[Artist, Event], tuple[bool, dict]]\n",
      "        pickradius: float\n",
      "        rasterized: bool\n",
      "        sketch_params: (scale: float, length: float, randomness: float)\n",
      "        snap: bool or None\n",
      "        solid_capstyle: `.CapStyle` or {'butt', 'projecting', 'round'}\n",
      "        solid_joinstyle: `.JoinStyle` or {'miter', 'round', 'bevel'}\n",
      "        transform: unknown\n",
      "        url: str\n",
      "        visible: bool\n",
      "        xdata: 1D array\n",
      "        ydata: 1D array\n",
      "        zorder: float\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scatter : XY scatter plot with markers of varying size and/or color (\n",
      "        sometimes also called bubble chart).\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    **Format Strings**\n",
      "    \n",
      "    A format string consists of a part for color, marker and line::\n",
      "    \n",
      "        fmt = '[marker][line][color]'\n",
      "    \n",
      "    Each of them is optional. If not provided, the value from the style\n",
      "    cycle is used. Exception: If ``line`` is given, but no ``marker``,\n",
      "    the data will be a line without markers.\n",
      "    \n",
      "    Other combinations such as ``[color][marker][line]`` are also\n",
      "    supported, but note that their parsing may be ambiguous.\n",
      "    \n",
      "    **Markers**\n",
      "    \n",
      "    =============   ===============================\n",
      "    character       description\n",
      "    =============   ===============================\n",
      "    ``'.'``         point marker\n",
      "    ``','``         pixel marker\n",
      "    ``'o'``         circle marker\n",
      "    ``'v'``         triangle_down marker\n",
      "    ``'^'``         triangle_up marker\n",
      "    ``'<'``         triangle_left marker\n",
      "    ``'>'``         triangle_right marker\n",
      "    ``'1'``         tri_down marker\n",
      "    ``'2'``         tri_up marker\n",
      "    ``'3'``         tri_left marker\n",
      "    ``'4'``         tri_right marker\n",
      "    ``'8'``         octagon marker\n",
      "    ``'s'``         square marker\n",
      "    ``'p'``         pentagon marker\n",
      "    ``'P'``         plus (filled) marker\n",
      "    ``'*'``         star marker\n",
      "    ``'h'``         hexagon1 marker\n",
      "    ``'H'``         hexagon2 marker\n",
      "    ``'+'``         plus marker\n",
      "    ``'x'``         x marker\n",
      "    ``'X'``         x (filled) marker\n",
      "    ``'D'``         diamond marker\n",
      "    ``'d'``         thin_diamond marker\n",
      "    ``'|'``         vline marker\n",
      "    ``'_'``         hline marker\n",
      "    =============   ===============================\n",
      "    \n",
      "    **Line Styles**\n",
      "    \n",
      "    =============    ===============================\n",
      "    character        description\n",
      "    =============    ===============================\n",
      "    ``'-'``          solid line style\n",
      "    ``'--'``         dashed line style\n",
      "    ``'-.'``         dash-dot line style\n",
      "    ``':'``          dotted line style\n",
      "    =============    ===============================\n",
      "    \n",
      "    Example format strings::\n",
      "    \n",
      "        'b'    # blue markers with default shape\n",
      "        'or'   # red circles\n",
      "        '-g'   # green solid line\n",
      "        '--'   # dashed line with default color\n",
      "        '^k:'  # black triangle_up markers connected by a dotted line\n",
      "    \n",
      "    **Colors**\n",
      "    \n",
      "    The supported color abbreviations are the single letter codes\n",
      "    \n",
      "    =============    ===============================\n",
      "    character        color\n",
      "    =============    ===============================\n",
      "    ``'b'``          blue\n",
      "    ``'g'``          green\n",
      "    ``'r'``          red\n",
      "    ``'c'``          cyan\n",
      "    ``'m'``          magenta\n",
      "    ``'y'``          yellow\n",
      "    ``'k'``          black\n",
      "    ``'w'``          white\n",
      "    =============    ===============================\n",
      "    \n",
      "    and the ``'CN'`` colors that index into the default property cycle.\n",
      "    \n",
      "    If the color is the only part of the format string, you can\n",
      "    additionally use any  `matplotlib.colors` spec, e.g. full names\n",
      "    (``'green'``) or hex strings (``'#008000'``).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(plt.plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    model= LogisticRegression(random_state=42,max_iter=1000,solver='sag')\n",
    "    model.fit(xtrain,ytrain)\n",
    "    predict=model.predict(xtest)\n",
    "    predict1=model.predict(xtrain)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9360936093609361"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest,predict)\n",
    "v=accuracy_score(ytrain,predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rajes\\\\wafer_detection\\\\notebook'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\rajes\\\\wafer_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('data_ingestion/input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=df1[df1['Good/Bad'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(v,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Wafer</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "      <th>Good/Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-501</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>...</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wafer-502</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wafer-503</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wafer-504</td>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>1236.5212</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Wafer-505</td>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>3469</td>\n",
       "      <td>Wafer-396</td>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1425.1041</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>...</td>\n",
       "      <td>31.3771</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3470</th>\n",
       "      <td>3470</td>\n",
       "      <td>Wafer-397</td>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1202.4520</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>3471</td>\n",
       "      <td>Wafer-398</td>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1657.3518</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>...</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3472</th>\n",
       "      <td>3472</td>\n",
       "      <td>Wafer-399</td>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1351.9648</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3473</th>\n",
       "      <td>3473</td>\n",
       "      <td>Wafer-400</td>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1448.8499</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  593 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      Wafer  Sensor-1  Sensor-2   Sensor-3   Sensor-4  \\\n",
       "0              0  Wafer-501   3076.81   2158.75  2208.2334  1517.0152   \n",
       "1              1  Wafer-502   2951.62   2511.92  2253.5111  1397.5060   \n",
       "2              2  Wafer-503   2930.42   2505.17  2235.0556  1302.6607   \n",
       "3              3  Wafer-504   2997.28   2357.99  2141.0667  1236.5212   \n",
       "4              4  Wafer-505   3025.10   2475.18  2235.0556  1302.6607   \n",
       "...          ...        ...       ...       ...        ...        ...   \n",
       "3469        3469  Wafer-396   3079.17   2405.56  2217.3777  1425.1041   \n",
       "3470        3470  Wafer-397   2911.37   2541.21  2207.8111  1202.4520   \n",
       "3471        3471  Wafer-398   3085.57   2364.78  2178.6889  1657.3518   \n",
       "3472        3472  Wafer-399   3053.49   2457.08  2172.5333  1351.9648   \n",
       "3473        3473  Wafer-400   3120.68   2396.40  2177.0222  1448.8499   \n",
       "\n",
       "      Sensor-5  Sensor-6  Sensor-7  Sensor-8  ...  Sensor-582  Sensor-583  \\\n",
       "0       1.0980     100.0  110.1900    0.1247  ...     64.2405      0.5016   \n",
       "1       0.9660     100.0  109.7611    0.1210  ...      0.0000      0.4953   \n",
       "2       1.6347     100.0  109.9856    0.1230  ...         NaN      0.4958   \n",
       "3       0.9698     100.0   98.3344    0.1238  ...         NaN      0.4962   \n",
       "4       1.6347     100.0  109.9856    0.1230  ...         NaN      0.4983   \n",
       "...        ...       ...       ...       ...  ...         ...         ...   \n",
       "3469    1.7585     100.0  106.2556    0.1200  ...     31.3771      0.5080   \n",
       "3470    1.6219     100.0  108.7689    0.1212  ...         NaN         NaN   \n",
       "3471    1.6603     100.0  100.8022    0.1229  ...    109.5996      0.4986   \n",
       "3472    1.6377     100.0  103.8800    0.1243  ...         NaN      0.4981   \n",
       "3473    1.5565     100.0  103.2567    0.1232  ...         NaN      0.4975   \n",
       "\n",
       "      Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n",
       "0         0.0152      0.0040      3.0319      0.0465      0.0299      0.0090   \n",
       "1         0.0105      0.0037      2.1266     -0.0012      0.0252      0.0081   \n",
       "2         0.0111      0.0033      2.2296     -0.0012      0.0252      0.0081   \n",
       "3         0.0086      0.0024      1.7297     -0.0012      0.0252      0.0081   \n",
       "4         0.0159      0.0041      3.1927     -0.0012      0.0252      0.0081   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3469      0.0139      0.0039      2.7328      0.0234      0.0073      0.0024   \n",
       "3470         NaN         NaN         NaN      0.0234      0.0073      0.0024   \n",
       "3471      0.0147      0.0038      2.9493      0.0142      0.0156      0.0044   \n",
       "3472      0.0132      0.0035      2.6491      0.0142      0.0156      0.0044   \n",
       "3473      0.0140      0.0036      2.8098      0.0142      0.0156      0.0044   \n",
       "\n",
       "      Sensor-590  Good/Bad  \n",
       "0        64.2405      -1.0  \n",
       "1         0.0000      -1.0  \n",
       "2         0.0000      -1.0  \n",
       "3         0.0000      -1.0  \n",
       "4         0.0000      -1.0  \n",
       "...          ...       ...  \n",
       "3469     31.3771      -1.0  \n",
       "3470     31.3771      -1.0  \n",
       "3471    109.5996      -1.0  \n",
       "3472    109.5996      -1.0  \n",
       "3473    109.5996      -1.0  \n",
       "\n",
       "[3074 rows x 593 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Wafer</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "      <th>Good/Bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-501</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>...</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Wafer-502</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Wafer-503</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Wafer-504</td>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>1236.5212</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Wafer-505</td>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3469</td>\n",
       "      <td>3469</td>\n",
       "      <td>Wafer-396</td>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1425.1041</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>...</td>\n",
       "      <td>31.3771</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>3470</td>\n",
       "      <td>3470</td>\n",
       "      <td>Wafer-397</td>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1202.4520</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3471</td>\n",
       "      <td>3471</td>\n",
       "      <td>Wafer-398</td>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1657.3518</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>...</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3472</td>\n",
       "      <td>3472</td>\n",
       "      <td>Wafer-399</td>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1351.9648</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3473</td>\n",
       "      <td>3473</td>\n",
       "      <td>Wafer-400</td>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1448.8499</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  594 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Unnamed: 0.1      Wafer  Sensor-1  Sensor-2   Sensor-3  \\\n",
       "0              0             0  Wafer-501   3076.81   2158.75  2208.2334   \n",
       "1              1             1  Wafer-502   2951.62   2511.92  2253.5111   \n",
       "2              2             2  Wafer-503   2930.42   2505.17  2235.0556   \n",
       "3              3             3  Wafer-504   2997.28   2357.99  2141.0667   \n",
       "4              4             4  Wafer-505   3025.10   2475.18  2235.0556   \n",
       "...          ...           ...        ...       ...       ...        ...   \n",
       "3069        3469          3469  Wafer-396   3079.17   2405.56  2217.3777   \n",
       "3070        3470          3470  Wafer-397   2911.37   2541.21  2207.8111   \n",
       "3071        3471          3471  Wafer-398   3085.57   2364.78  2178.6889   \n",
       "3072        3472          3472  Wafer-399   3053.49   2457.08  2172.5333   \n",
       "3073        3473          3473  Wafer-400   3120.68   2396.40  2177.0222   \n",
       "\n",
       "       Sensor-4  Sensor-5  Sensor-6  Sensor-7  ...  Sensor-582  Sensor-583  \\\n",
       "0     1517.0152    1.0980     100.0  110.1900  ...     64.2405      0.5016   \n",
       "1     1397.5060    0.9660     100.0  109.7611  ...      0.0000      0.4953   \n",
       "2     1302.6607    1.6347     100.0  109.9856  ...         NaN      0.4958   \n",
       "3     1236.5212    0.9698     100.0   98.3344  ...         NaN      0.4962   \n",
       "4     1302.6607    1.6347     100.0  109.9856  ...         NaN      0.4983   \n",
       "...         ...       ...       ...       ...  ...         ...         ...   \n",
       "3069  1425.1041    1.7585     100.0  106.2556  ...     31.3771      0.5080   \n",
       "3070  1202.4520    1.6219     100.0  108.7689  ...         NaN         NaN   \n",
       "3071  1657.3518    1.6603     100.0  100.8022  ...    109.5996      0.4986   \n",
       "3072  1351.9648    1.6377     100.0  103.8800  ...         NaN      0.4981   \n",
       "3073  1448.8499    1.5565     100.0  103.2567  ...         NaN      0.4975   \n",
       "\n",
       "      Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n",
       "0         0.0152      0.0040      3.0319      0.0465      0.0299      0.0090   \n",
       "1         0.0105      0.0037      2.1266     -0.0012      0.0252      0.0081   \n",
       "2         0.0111      0.0033      2.2296     -0.0012      0.0252      0.0081   \n",
       "3         0.0086      0.0024      1.7297     -0.0012      0.0252      0.0081   \n",
       "4         0.0159      0.0041      3.1927     -0.0012      0.0252      0.0081   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069      0.0139      0.0039      2.7328      0.0234      0.0073      0.0024   \n",
       "3070         NaN         NaN         NaN      0.0234      0.0073      0.0024   \n",
       "3071      0.0147      0.0038      2.9493      0.0142      0.0156      0.0044   \n",
       "3072      0.0132      0.0035      2.6491      0.0142      0.0156      0.0044   \n",
       "3073      0.0140      0.0036      2.8098      0.0142      0.0156      0.0044   \n",
       "\n",
       "      Sensor-590  Good/Bad  \n",
       "0        64.2405      -1.0  \n",
       "1         0.0000      -1.0  \n",
       "2         0.0000      -1.0  \n",
       "3         0.0000      -1.0  \n",
       "4         0.0000      -1.0  \n",
       "...          ...       ...  \n",
       "3069     31.3771      -1.0  \n",
       "3070     31.3771      -1.0  \n",
       "3071    109.5996      -1.0  \n",
       "3072    109.5996      -1.0  \n",
       "3073    109.5996      -1.0  \n",
       "\n",
       "[3074 rows x 594 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>clusters</th>\n",
       "      <th>output_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.031900</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.126600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.229600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.729700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.498300</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.192700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.732800</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.501533</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.368433</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.949300</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.498100</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.649100</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.809800</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  405 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0      3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1      2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2      2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3      2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4      3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556    1.4794   \n",
       "3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689    1.5322   \n",
       "3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022    1.4945   \n",
       "3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800    1.5680   \n",
       "3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567    1.4920   \n",
       "\n",
       "      Sensor-10  Sensor-11  Sensor-12  ...  Sensor-581  Sensor-583  \\\n",
       "0        0.0089     0.0052     0.9655  ...    0.009000    0.501600   \n",
       "1        0.0119    -0.0082     0.9572  ...    0.008100    0.495300   \n",
       "2       -0.0143     0.0017     0.9702  ...    0.007333    0.495800   \n",
       "3       -0.0534    -0.0284     0.9708  ...    0.004733    0.496200   \n",
       "4       -0.0078    -0.0005     0.9680  ...    0.005867    0.498300   \n",
       "...         ...        ...        ...  ...         ...         ...   \n",
       "3069    -0.0198    -0.0004     0.9535  ...    0.002400    0.508000   \n",
       "3070     0.0205    -0.0213     0.9561  ...    0.005700    0.501533   \n",
       "3071     0.0247    -0.0049     0.9560  ...    0.004400    0.498600   \n",
       "3072     0.0009     0.0094     0.9560  ...    0.006233    0.498100   \n",
       "3073    -0.0095     0.0165     0.9525  ...    0.005333    0.497500   \n",
       "\n",
       "      Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n",
       "0         0.0152      0.0040    3.031900      0.0465      0.0299      0.0090   \n",
       "1         0.0105      0.0037    2.126600     -0.0012      0.0252      0.0081   \n",
       "2         0.0111      0.0033    2.229600     -0.0012      0.0252      0.0081   \n",
       "3         0.0086      0.0024    1.729700     -0.0012      0.0252      0.0081   \n",
       "4         0.0159      0.0041    3.192700     -0.0012      0.0252      0.0081   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069      0.0139      0.0039    2.732800      0.0234      0.0073      0.0024   \n",
       "3070      0.0169      0.0040    3.368433      0.0234      0.0073      0.0024   \n",
       "3071      0.0147      0.0038    2.949300      0.0142      0.0156      0.0044   \n",
       "3072      0.0132      0.0035    2.649100      0.0142      0.0156      0.0044   \n",
       "3073      0.0140      0.0036    2.809800      0.0142      0.0156      0.0044   \n",
       "\n",
       "      clusters  output_feature  \n",
       "0            0            -1.0  \n",
       "1            0            -1.0  \n",
       "2            3            -1.0  \n",
       "3            0            -1.0  \n",
       "4            1            -1.0  \n",
       "...        ...             ...  \n",
       "3069         3            -1.0  \n",
       "3070         0            -1.0  \n",
       "3071         3            -1.0  \n",
       "3072         1            -1.0  \n",
       "3073         0            -1.0  \n",
       "\n",
       "[3074 rows x 405 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-579</th>\n",
       "      <th>Sensor-580</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.031900</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.126600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.229600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028033</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.729700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.498300</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.192700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.732800</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.501533</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.368433</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.949300</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.498100</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.649100</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.809800</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0      3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1      2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2      2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3      2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4      3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556    1.4794   \n",
       "3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689    1.5322   \n",
       "3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022    1.4945   \n",
       "3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800    1.5680   \n",
       "3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567    1.4920   \n",
       "\n",
       "      Sensor-10  Sensor-11  Sensor-12  ...  Sensor-579  Sensor-580  \\\n",
       "0        0.0089     0.0052     0.9655  ...    0.046500    0.029900   \n",
       "1        0.0119    -0.0082     0.9572  ...   -0.001200    0.025200   \n",
       "2       -0.0143     0.0017     0.9702  ...    0.027600    0.020000   \n",
       "3       -0.0534    -0.0284     0.9708  ...    0.028033    0.013267   \n",
       "4       -0.0078    -0.0005     0.9680  ...    0.027500    0.018433   \n",
       "...         ...        ...        ...  ...         ...         ...   \n",
       "3069    -0.0198    -0.0004     0.9535  ...    0.023400    0.007300   \n",
       "3070     0.0205    -0.0213     0.9561  ...    0.017433    0.014833   \n",
       "3071     0.0247    -0.0049     0.9560  ...    0.014200    0.015600   \n",
       "3072     0.0009     0.0094     0.9560  ...    0.027000    0.020033   \n",
       "3073    -0.0095     0.0165     0.9525  ...    0.027567    0.016700   \n",
       "\n",
       "      Sensor-581  Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  \\\n",
       "0       0.009000    0.501600      0.0152      0.0040    3.031900      0.0465   \n",
       "1       0.008100    0.495300      0.0105      0.0037    2.126600     -0.0012   \n",
       "2       0.007333    0.495800      0.0111      0.0033    2.229600     -0.0012   \n",
       "3       0.004733    0.496200      0.0086      0.0024    1.729700     -0.0012   \n",
       "4       0.005867    0.498300      0.0159      0.0041    3.192700     -0.0012   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069    0.002400    0.508000      0.0139      0.0039    2.732800      0.0234   \n",
       "3070    0.005700    0.501533      0.0169      0.0040    3.368433      0.0234   \n",
       "3071    0.004400    0.498600      0.0147      0.0038    2.949300      0.0142   \n",
       "3072    0.006233    0.498100      0.0132      0.0035    2.649100      0.0142   \n",
       "3073    0.005333    0.497500      0.0140      0.0036    2.809800      0.0142   \n",
       "\n",
       "      Sensor-588  Sensor-589  \n",
       "0         0.0299      0.0090  \n",
       "1         0.0252      0.0081  \n",
       "2         0.0252      0.0081  \n",
       "3         0.0252      0.0081  \n",
       "4         0.0252      0.0081  \n",
       "...          ...         ...  \n",
       "3069      0.0073      0.0024  \n",
       "3070      0.0073      0.0024  \n",
       "3071      0.0156      0.0044  \n",
       "3072      0.0156      0.0044  \n",
       "3073      0.0156      0.0044  \n",
       "\n",
       "[3074 rows x 403 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Good/Bad'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    model= SVC(random_state=42,max_iter=1000)\n",
    "    model.fit(xtrain,ytrain)\n",
    "    predict=model.predict(xtest)\n",
    "    predict1=model.predict(xtrain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=accuracy_score(ytest,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475890985324947"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    model=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "    model.fit(xtrain,ytrain)\n",
    "    predict=model.predict(xtest)\n",
    "    predict1=model.predict(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class XGBClassifier in module xgboost.sklearn:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  XGBClassifier(*, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: bool = False, **kwargs: Any) -> None\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |      n_estimators : int\n",
      " |          Number of boosting rounds.\n",
      " |  \n",
      " |      max_depth :  Optional[int]\n",
      " |          Maximum tree depth for base learners.\n",
      " |      max_leaves :\n",
      " |          Maximum number of leaves; 0 indicates no limit.\n",
      " |      max_bin :\n",
      " |          If using histogram-based algorithm, maximum number of bins per feature\n",
      " |      grow_policy :\n",
      " |          Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow\n",
      " |          depth-wise. 1: favor splitting at nodes with highest loss change.\n",
      " |      learning_rate : Optional[float]\n",
      " |          Boosting learning rate (xgb's \"eta\")\n",
      " |      verbosity : Optional[int]\n",
      " |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      " |      objective : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      " |          Specify the learning task and the corresponding learning objective or\n",
      " |          a custom objective function to be used (see note below).\n",
      " |      booster: Optional[str]\n",
      " |          Specify which booster to use: gbtree, gblinear or dart.\n",
      " |      tree_method: Optional[str]\n",
      " |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      " |          default, XGBoost will choose the most conservative option available.  It's\n",
      " |          recommended to study this option from the parameters document :doc:`tree method\n",
      " |          </treemethod>`\n",
      " |      n_jobs : Optional[int]\n",
      " |          Number of parallel threads used to run xgboost.  When used with other Scikit-Learn\n",
      " |          algorithms like grid search, you may choose which algorithm to parallelize and\n",
      " |          balance the threads.  Creating thread contention will significantly slow down both\n",
      " |          algorithms.\n",
      " |      gamma : Optional[float]\n",
      " |          (min_split_loss) Minimum loss reduction required to make a further partition on a\n",
      " |          leaf node of the tree.\n",
      " |      min_child_weight : Optional[float]\n",
      " |          Minimum sum of instance weight(hessian) needed in a child.\n",
      " |      max_delta_step : Optional[float]\n",
      " |          Maximum delta step we allow each tree's weight estimation to be.\n",
      " |      subsample : Optional[float]\n",
      " |          Subsample ratio of the training instance.\n",
      " |      sampling_method :\n",
      " |          Sampling method. Used only by `gpu_hist` tree method.\n",
      " |            - `uniform`: select random training instances uniformly.\n",
      " |            - `gradient_based` select random training instances with higher probability when\n",
      " |              the gradient and hessian are larger. (cf. CatBoost)\n",
      " |      colsample_bytree : Optional[float]\n",
      " |          Subsample ratio of columns when constructing each tree.\n",
      " |      colsample_bylevel : Optional[float]\n",
      " |          Subsample ratio of columns for each level.\n",
      " |      colsample_bynode : Optional[float]\n",
      " |          Subsample ratio of columns for each split.\n",
      " |      reg_alpha : Optional[float]\n",
      " |          L1 regularization term on weights (xgb's alpha).\n",
      " |      reg_lambda : Optional[float]\n",
      " |          L2 regularization term on weights (xgb's lambda).\n",
      " |      scale_pos_weight : Optional[float]\n",
      " |          Balancing of positive and negative weights.\n",
      " |      base_score : Optional[float]\n",
      " |          The initial prediction score of all instances, global bias.\n",
      " |      random_state : Optional[Union[numpy.random.RandomState, int]]\n",
      " |          Random number seed.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      " |             it uses Hogwild algorithm.\n",
      " |  \n",
      " |      missing : float, default np.nan\n",
      " |          Value in the data which needs to be present as a missing value.\n",
      " |      num_parallel_tree: Optional[int]\n",
      " |          Used for boosting random forest.\n",
      " |      monotone_constraints : Optional[Union[Dict[str, int], str]]\n",
      " |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      " |          for more information.\n",
      " |      interaction_constraints : Optional[Union[str, List[Tuple[str]]]]\n",
      " |          Constraints for interaction representing permitted interactions.  The\n",
      " |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      " |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      " |          allowed to interact with each other.  See :doc:`tutorial\n",
      " |          </tutorials/feature_interaction_constraint>` for more information\n",
      " |      importance_type: Optional[str]\n",
      " |          The feature importance type for the feature_importances\\_ property:\n",
      " |  \n",
      " |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      " |            \"total_cover\".\n",
      " |          * For linear model, only \"weight\" is defined and it's the normalized coefficients\n",
      " |            without bias.\n",
      " |  \n",
      " |      gpu_id : Optional[int]\n",
      " |          Device ordinal.\n",
      " |      validate_parameters : Optional[bool]\n",
      " |          Give warnings for unknown parameter.\n",
      " |      predictor : Optional[str]\n",
      " |          Force XGBoost to use specific predictor, available choices are [cpu_predictor,\n",
      " |          gpu_predictor].\n",
      " |      enable_categorical : bool\n",
      " |  \n",
      " |          .. versionadded:: 1.5.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame\n",
      " |          should be used to specify categorical data type.  Also, JSON/UBJSON\n",
      " |          serialization format is required.\n",
      " |  \n",
      " |      max_cat_to_onehot : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      " |          for categorical data.  When number of categories is lesser than the threshold\n",
      " |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      " |          into children nodes.  Only relevant for regression and binary classification.\n",
      " |          See :doc:`Categorical Data </tutorials/categorical>` for details.\n",
      " |  \n",
      " |      eval_metric : Optional[Union[str, List[str], Callable]]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      " |          string or list of strings as names of predefined metric in XGBoost (See\n",
      " |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any other\n",
      " |          user defined metric that looks like `sklearn.metrics`.\n",
      " |  \n",
      " |          If custom objective is also provided, then custom metric should implement the\n",
      " |          corresponding reverse link function.\n",
      " |  \n",
      " |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      " |          object is provided, it's assumed to be a cost function and by default XGBoost will\n",
      " |          minimize the result during early stopping.\n",
      " |  \n",
      " |          For advanced usage on Early stopping like directly choosing to maximize instead of\n",
      " |          minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      " |  \n",
      " |          See :doc:`Custom Objective and Evaluation Metric </tutorials/custom_metric_obj>`\n",
      " |          for more.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |               This parameter replaces `eval_metric` in :py:meth:`fit` method.  The old one\n",
      " |               receives un-transformed prediction regardless of whether custom objective is\n",
      " |               being used.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              from sklearn.datasets import load_diabetes\n",
      " |              from sklearn.metrics import mean_absolute_error\n",
      " |              X, y = load_diabetes(return_X_y=True)\n",
      " |              reg = xgb.XGBRegressor(\n",
      " |                  tree_method=\"hist\",\n",
      " |                  eval_metric=mean_absolute_error,\n",
      " |              )\n",
      " |              reg.fit(X, y, eval_set=[(X, y)])\n",
      " |  \n",
      " |      early_stopping_rounds : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Activates early stopping. Validation metric needs to improve at least once in\n",
      " |          every **early_stopping_rounds** round(s) to continue training.  Requires at least\n",
      " |          one item in **eval_set** in :py:meth:`fit`.\n",
      " |  \n",
      " |          The method returns the model from the last iteration (not the best one).  If\n",
      " |          there's more than one item in **eval_set**, the last entry will be used for early\n",
      " |          stopping.  If there's more than one metric in **eval_metric**, the last metric\n",
      " |          will be used for early stopping.\n",
      " |  \n",
      " |          If early stopping occurs, the model will have three additional fields:\n",
      " |          :py:attr:`best_score`, :py:attr:`best_iteration` and\n",
      " |          :py:attr:`best_ntree_limit`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |              This parameter replaces `early_stopping_rounds` in :py:meth:`fit` method.\n",
      " |  \n",
      " |      callbacks : Optional[List[TrainingCallback]]\n",
      " |          List of callback functions that are applied at end of each iteration.\n",
      " |          It is possible to use predefined callbacks by using\n",
      " |          :ref:`Callback API <callback_api>`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             States in callback are not preserved during training, which means callback\n",
      " |             objects can not be reused for multiple training sessions without\n",
      " |             reinitialization or deepcopy.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              for params in parameters_grid:\n",
      " |                  # be sure to (re)initialize the callbacks before each run\n",
      " |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      " |                  xgboost.train(params, Xy, callbacks=callbacks)\n",
      " |  \n",
      " |      kwargs : dict, optional\n",
      " |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      " |          can be found :doc:`here </parameter>`.\n",
      " |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      " |          dict simultaneously will result in a TypeError.\n",
      " |  \n",
      " |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      " |  \n",
      " |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      " |              that parameters passed via this argument will interact properly\n",
      " |              with scikit-learn.\n",
      " |  \n",
      " |          .. note::  Custom objective function\n",
      " |  \n",
      " |              A custom objective function can be provided for the ``objective``\n",
      " |              parameter. In this case, it should have the signature\n",
      " |              ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |              y_true: array_like of shape [n_samples]\n",
      " |                  The target values\n",
      " |              y_pred: array_like of shape [n_samples]\n",
      " |                  The predicted values\n",
      " |  \n",
      " |              grad: array_like of shape [n_samples]\n",
      " |                  The value of the gradient for each sample point.\n",
      " |              hess: array_like of shape [n_samples]\n",
      " |                  The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: bool = False, **kwargs: Any) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X: Any, y: Any, *, sample_weight: Union[Any, NoneType] = None, base_margin: Union[Any, NoneType] = None, eval_set: Union[Sequence[Tuple[Any, Any]], NoneType] = None, eval_metric: Union[str, Sequence[str], Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None, early_stopping_rounds: Union[int, NoneType] = None, verbose: Union[bool, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Union[Sequence[Any], NoneType] = None, base_margin_eval_set: Union[Sequence[Any], NoneType] = None, feature_weights: Union[Any, NoneType] = None, callbacks: Union[Sequence[xgboost.callback.TrainingCallback], NoneType] = None) -> 'XGBClassifier'\n",
      " |      Fit gradient boosting classifier.\n",
      " |      \n",
      " |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      " |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      " |      pass ``xgb_model`` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Feature matrix\n",
      " |      y :\n",
      " |          Labels\n",
      " |      sample_weight :\n",
      " |          instance weights\n",
      " |      base_margin :\n",
      " |          global bias for each instance.\n",
      " |      eval_set :\n",
      " |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      " |          metrics will be computed.\n",
      " |          Validation metrics will help us track the performance of the model.\n",
      " |      \n",
      " |      eval_metric : str, list of str, or callable, optional\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `eval_metric` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |      \n",
      " |      early_stopping_rounds : int\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `early_stopping_rounds` in :py:meth:`__init__` or\n",
      " |              :py:meth:`set_params` instead.\n",
      " |      verbose :\n",
      " |          If `verbose` and an evaluation set is used, writes the evaluation metric\n",
      " |          measured on the validation set to stderr.\n",
      " |      xgb_model :\n",
      " |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |      sample_weight_eval_set :\n",
      " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      " |          object storing instance weights for the i-th validation set.\n",
      " |      base_margin_eval_set :\n",
      " |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      " |          object storing base margin for the i-th validation set.\n",
      " |      feature_weights :\n",
      " |          Weight for each feature, defines the probability of each feature being\n",
      " |          selected when colsample is being used.  All values must be greater than 0,\n",
      " |          otherwise a `ValueError` is thrown.\n",
      " |      \n",
      " |      callbacks :\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `callbacks` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |  \n",
      " |  predict(self, X: Any, output_margin: bool = False, ntree_limit: Union[int, NoneType] = None, validate_features: bool = True, base_margin: Union[Any, NoneType] = None, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Predict with `X`.  If the model is trained with early stopping, then `best_iteration`\n",
      " |      is used automatically.  For tree models, when data is on GPU, like cupy array or\n",
      " |      cuDF dataframe and `predictor` is not specified, the prediction is run on GPU\n",
      " |      automatically, otherwise it will run on CPU.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Data to predict with.\n",
      " |      output_margin :\n",
      " |          Whether to output the raw untransformed margin value.\n",
      " |      ntree_limit :\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features :\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin :\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      " |          20)``, then only the forests built during [10, 20) (half open set) rounds are\n",
      " |          used in this prediction.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction\n",
      " |  \n",
      " |  predict_proba(self, X: Any, ntree_limit: Union[int, NoneType] = None, validate_features: bool = True, base_margin: Union[Any, NoneType] = None, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Predict the probability of each `X` example being of a given class.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix.\n",
      " |      ntree_limit : int\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin : array_like\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      " |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      " |          used in this prediction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      " |          probability of each data example being of a given class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __sklearn_is_fitted__(self) -> bool\n",
      " |  \n",
      " |  apply(self, X: Any, ntree_limit: int = 0, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Return the predicted leaf every tree for each sample. If the model is trained with\n",
      " |      early stopping, then `best_iteration` is used automatically.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      iteration_range :\n",
      " |          See :py:meth:`predict`.\n",
      " |      \n",
      " |      ntree_limit :\n",
      " |          Deprecated, use ``iteration_range`` instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      " |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      " |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      " |      function.\n",
      " |      \n",
      " |      The returned evaluation result is a dictionary:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result\n",
      " |  \n",
      " |  get_booster(self) -> xgboost.core.Booster\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_num_boosting_rounds(self) -> int\n",
      " |      Gets the number of xgboost boosting rounds.\n",
      " |  \n",
      " |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self) -> Dict[str, Any]\n",
      " |      Get xgboost specific parameters.\n",
      " |  \n",
      " |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      " |      Load the model from a file or bytearray. Path to file can be local\n",
      " |      or as an URI.\n",
      " |      \n",
      " |      The model is loaded from XGBoost format which is universal among the various\n",
      " |      XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as\n",
      " |      feature_names) will not be loaded when using binary format.  To save those\n",
      " |      attributes, use JSON/UBJ instead.  See :doc:`Model IO </tutorials/saving_model>`\n",
      " |      for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.load_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.load_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname :\n",
      " |          Input file name or memory buffer(see also save_raw)\n",
      " |  \n",
      " |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      The model is saved in an XGBoost internal format which is universal among the\n",
      " |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      " |      (such as feature_names) will not be saved when using binary format.  To save\n",
      " |      those attributes, use JSON/UBJ instead. See :doc:`Model IO\n",
      " |      </tutorials/saving_model>` for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.save_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.save_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or os.PathLike\n",
      " |          Output file name\n",
      " |  \n",
      " |  set_params(self, **params: Any) -> 'XGBModel'\n",
      " |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      " |      allow unknown kwargs. This allows using the full range of xgboost\n",
      " |      parameters that are not defined as member variables in sklearn grid\n",
      " |      search.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from XGBModel:\n",
      " |  \n",
      " |  best_iteration\n",
      " |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      " |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      " |  \n",
      " |  best_ntree_limit\n",
      " |  \n",
      " |  best_score\n",
      " |      The best score obtained by early stopping.\n",
      " |  \n",
      " |  coef_\n",
      " |      Coefficients property\n",
      " |      \n",
      " |      .. note:: Coefficients are defined only for linear learners\n",
      " |      \n",
      " |          Coefficients are only defined when the linear model is chosen as\n",
      " |          base learner (`booster=gblinear`). It is not defined for other base\n",
      " |          learner types, such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Feature importances property, return depends on `importance_type` parameter.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      " |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      " |  \n",
      " |  feature_names_in_\n",
      " |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has feature\n",
      " |      names that are all strings.\n",
      " |  \n",
      " |  intercept_\n",
      " |      Intercept (bias) property\n",
      " |      \n",
      " |      .. note:: Intercept is defined only for linear learners\n",
      " |      \n",
      " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types,\n",
      " |          such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :py:meth:`fit`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9832285115303984"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrain,predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    ytrain_mapped = [1 if label == 1 else 0 for label in ytrain]\n",
    "    ytest_mapped = [1 if label == 1 else 0 for label in ytest]\n",
    "\n",
    "    # Now fit the XGBoost classifier using the mapped labels\n",
    "    model = XGBClassifier(n_estimators=100, random_state=42,learning_rate=1e-3)\n",
    "    model.fit(xtrain, ytrain_mapped)\n",
    "    predict = model.predict(xtest)\n",
    "    predict1 = model.predict(xtrain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      -1.0\n",
       "5      -1.0\n",
       "6      -1.0\n",
       "10     -1.0\n",
       "11     -1.0\n",
       "       ... \n",
       "3059   -1.0\n",
       "3065   -1.0\n",
       "3067   -1.0\n",
       "3069   -1.0\n",
       "3071   -1.0\n",
       "Name: output_feature, Length: 1588, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0405040504050405"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrain,predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:437: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:478: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\scipy\\optimize\\linesearch.py:327: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    }
   ],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    model=GridSearchCV(LogisticRegression(random_state=42,max_iter=1000,solver='sag'),param_grid=parameter,cv=5)\n",
    "    model.fit(xtrain,ytrain)\n",
    "    best_estimator=model.best_params_\n",
    "    best_score=model.best_score_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
      "\n",
      "class GridSearchCV(BaseSearchCV)\n",
      " |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |  \n",
      " |  Exhaustive search over specified parameter values for an estimator.\n",
      " |  \n",
      " |  Important members are fit, predict.\n",
      " |  \n",
      " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      " |  It also implements \"score_samples\", \"predict\", \"predict_proba\",\n",
      " |  \"decision_function\", \"transform\" and \"inverse_transform\" if they are\n",
      " |  implemented in the estimator used.\n",
      " |  \n",
      " |  The parameters of the estimator used to apply these methods are optimized\n",
      " |  by cross-validated grid-search over a parameter grid.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <grid_search>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator object\n",
      " |      This is assumed to implement the scikit-learn estimator interface.\n",
      " |      Either estimator needs to provide a ``score`` function,\n",
      " |      or ``scoring`` must be passed.\n",
      " |  \n",
      " |  param_grid : dict or list of dictionaries\n",
      " |      Dictionary with parameters names (`str`) as keys and lists of\n",
      " |      parameter settings to try as values, or a list of such\n",
      " |      dictionaries, in which case the grids spanned by each dictionary\n",
      " |      in the list are explored. This enables searching over any sequence\n",
      " |      of parameter settings.\n",
      " |  \n",
      " |  scoring : str, callable, list, tuple or dict, default=None\n",
      " |      Strategy to evaluate the performance of the cross-validated model on\n",
      " |      the test set.\n",
      " |  \n",
      " |      If `scoring` represents a single score, one can use:\n",
      " |  \n",
      " |      - a single string (see :ref:`scoring_parameter`);\n",
      " |      - a callable (see :ref:`scoring`) that returns a single value.\n",
      " |  \n",
      " |      If `scoring` represents multiple scores, one can use:\n",
      " |  \n",
      " |      - a list or tuple of unique strings;\n",
      " |      - a callable returning a dictionary where the keys are the metric\n",
      " |        names and the values are the metric scores;\n",
      " |      - a dictionary with metric names as keys and callables a values.\n",
      " |  \n",
      " |      See :ref:`multimetric_grid_search` for an example.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of jobs to run in parallel.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |      .. versionchanged:: v0.20\n",
      " |         `n_jobs` default changed from 1 to None\n",
      " |  \n",
      " |  refit : bool, str, or callable, default=True\n",
      " |      Refit an estimator using the best found parameters on the whole\n",
      " |      dataset.\n",
      " |  \n",
      " |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      " |      scorer that would be used to find the best parameters for refitting\n",
      " |      the estimator at the end.\n",
      " |  \n",
      " |      Where there are considerations other than maximum score in\n",
      " |      choosing a best estimator, ``refit`` can be set to a function which\n",
      " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      " |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      " |      according to the returned ``best_index_`` while the ``best_score_``\n",
      " |      attribute will not be available.\n",
      " |  \n",
      " |      The refitted estimator is made available at the ``best_estimator_``\n",
      " |      attribute and permits using ``predict`` directly on this\n",
      " |      ``GridSearchCV`` instance.\n",
      " |  \n",
      " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      " |      ``best_score_`` and ``best_params_`` will only be available if\n",
      " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      " |      scorer.\n",
      " |  \n",
      " |      See ``scoring`` parameter to know more about multiple metric\n",
      " |      evaluation.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          Support for callable added.\n",
      " |  \n",
      " |  cv : int, cross-validation generator or an iterable, default=None\n",
      " |      Determines the cross-validation splitting strategy.\n",
      " |      Possible inputs for cv are:\n",
      " |  \n",
      " |      - None, to use the default 5-fold cross validation,\n",
      " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      " |      - :term:`CV splitter`,\n",
      " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |  \n",
      " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      " |      other cases, :class:`KFold` is used. These splitters are instantiated\n",
      " |      with `shuffle=False` so the splits will be the same across calls.\n",
      " |  \n",
      " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      " |      cross-validation strategies that can be used here.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      " |  \n",
      " |  verbose : int\n",
      " |      Controls the verbosity: the higher, the more messages.\n",
      " |  \n",
      " |      - >1 : the computation time for each fold and parameter candidate is\n",
      " |        displayed;\n",
      " |      - >2 : the score is also displayed;\n",
      " |      - >3 : the fold and candidate parameter indexes are also displayed\n",
      " |        together with the starting time of the computation.\n",
      " |  \n",
      " |  pre_dispatch : int, or str, default='2*n_jobs'\n",
      " |      Controls the number of jobs that get dispatched during parallel\n",
      " |      execution. Reducing this number can be useful to avoid an\n",
      " |      explosion of memory consumption when more jobs get dispatched\n",
      " |      than CPUs can process. This parameter can be:\n",
      " |  \n",
      " |          - None, in which case all the jobs are immediately\n",
      " |            created and spawned. Use this for lightweight and\n",
      " |            fast-running jobs, to avoid delays due to on-demand\n",
      " |            spawning of the jobs\n",
      " |  \n",
      " |          - An int, giving the exact number of total jobs that are\n",
      " |            spawned\n",
      " |  \n",
      " |          - A str, giving an expression as a function of n_jobs,\n",
      " |            as in '2*n_jobs'\n",
      " |  \n",
      " |  error_score : 'raise' or numeric, default=np.nan\n",
      " |      Value to assign to the score if an error occurs in estimator fitting.\n",
      " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      " |      step, which will always raise the error.\n",
      " |  \n",
      " |  return_train_score : bool, default=False\n",
      " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      " |      scores.\n",
      " |      Computing training scores is used to get insights on how different\n",
      " |      parameter settings impact the overfitting/underfitting trade-off.\n",
      " |      However computing the scores on the training set can be computationally\n",
      " |      expensive and is not strictly required to select the parameters that\n",
      " |      yield the best generalization performance.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |      .. versionchanged:: 0.21\n",
      " |          Default value was changed from ``True`` to ``False``\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cv_results_ : dict of numpy (masked) ndarrays\n",
      " |      A dict with keys as column headers and values as columns, that can be\n",
      " |      imported into a pandas ``DataFrame``.\n",
      " |  \n",
      " |      For instance the below given table\n",
      " |  \n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      " |      +============+===========+============+=================+===+=========+\n",
      " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      " |      +------------+-----------+------------+-----------------+---+---------+\n",
      " |  \n",
      " |      will be represented by a ``cv_results_`` dict of::\n",
      " |  \n",
      " |          {\n",
      " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      " |                                       mask = [False False False False]...)\n",
      " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      " |                                      mask = [ True  True False False]...),\n",
      " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      " |                                       mask = [False False  True  True]...),\n",
      " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      " |          'rank_test_score'    : [2, 4, 3, 1],\n",
      " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      " |          }\n",
      " |  \n",
      " |      NOTE\n",
      " |  \n",
      " |      The key ``'params'`` is used to store a list of parameter\n",
      " |      settings dicts for all the parameter candidates.\n",
      " |  \n",
      " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      " |      ``std_score_time`` are all in seconds.\n",
      " |  \n",
      " |      For multi-metric evaluation, the scores for all the scorers are\n",
      " |      available in the ``cv_results_`` dict at the keys ending with that\n",
      " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      " |  \n",
      " |  best_estimator_ : estimator\n",
      " |      Estimator that was chosen by the search, i.e. estimator\n",
      " |      which gave highest score (or smallest loss if specified)\n",
      " |      on the left out data. Not available if ``refit=False``.\n",
      " |  \n",
      " |      See ``refit`` parameter for more information on allowed values.\n",
      " |  \n",
      " |  best_score_ : float\n",
      " |      Mean cross-validated score of the best_estimator\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |      This attribute is not available if ``refit`` is a function.\n",
      " |  \n",
      " |  best_params_ : dict\n",
      " |      Parameter setting that gave the best results on the hold out data.\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  best_index_ : int\n",
      " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      " |      candidate parameter setting.\n",
      " |  \n",
      " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      " |      the parameter setting for the best model, that gives the highest\n",
      " |      mean score (``search.best_score_``).\n",
      " |  \n",
      " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      " |      specified.\n",
      " |  \n",
      " |  scorer_ : function or a dict\n",
      " |      Scorer function used on the held out data to choose the best\n",
      " |      parameters for the model.\n",
      " |  \n",
      " |      For multi-metric evaluation, this attribute holds the validated\n",
      " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      " |  \n",
      " |  n_splits_ : int\n",
      " |      The number of cross-validation splits (folds/iterations).\n",
      " |  \n",
      " |  refit_time_ : float\n",
      " |      Seconds used for refitting the best model on the whole dataset.\n",
      " |  \n",
      " |      This is present only if ``refit`` is not False.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  multimetric_ : bool\n",
      " |      Whether or not the scorers compute several metrics.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels. This is present only if ``refit`` is specified and\n",
      " |      the underlying estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `n_features_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Only defined if\n",
      " |      `best_estimator_` is defined (see the documentation for the `refit`\n",
      " |      parameter for more details) and that `best_estimator_` exposes\n",
      " |      `feature_names_in_` when fit.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The parameters selected are those that maximize the score of the left out\n",
      " |  data, unless an explicit score is passed in which case it is used instead.\n",
      " |  \n",
      " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      " |  reasons if individual jobs take very little time, but may raise errors if\n",
      " |  the dataset is large and not enough memory is available.  A workaround in\n",
      " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      " |  n_jobs`.\n",
      " |  \n",
      " |  See Also\n",
      " |  ---------\n",
      " |  ParameterGrid : Generates all the combinations of a hyperparameter grid.\n",
      " |  train_test_split : Utility function to split the data into a development\n",
      " |      set usable for fitting a GridSearchCV instance and an evaluation set\n",
      " |      for its final evaluation.\n",
      " |  sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
      " |      loss function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn import svm, datasets\n",
      " |  >>> from sklearn.model_selection import GridSearchCV\n",
      " |  >>> iris = datasets.load_iris()\n",
      " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      " |  >>> svc = svm.SVC()\n",
      " |  >>> clf = GridSearchCV(svc, parameters)\n",
      " |  >>> clf.fit(iris.data, iris.target)\n",
      " |  GridSearchCV(estimator=SVC(),\n",
      " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      " |  >>> sorted(clf.cv_results_.keys())\n",
      " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      " |   'param_C', 'param_kernel', 'params',...\n",
      " |   'rank_test_score', 'split0_test_score',...\n",
      " |   'split2_test_score', ...\n",
      " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GridSearchCV\n",
      " |      BaseSearchCV\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseSearchCV:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Call decision_function on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``decision_function``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,) or (n_samples, n_classes)                 or (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Result of the decision function for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      " |      Run fit with all sets of parameters.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      groups : array-like of shape (n_samples,), default=None\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      " |      \n",
      " |      **fit_params : dict of str -> object\n",
      " |          Parameters passed to the ``fit`` method of the estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Instance of fitted estimator.\n",
      " |  \n",
      " |  inverse_transform(self, Xt)\n",
      " |      Call inverse_transform on the estimator with the best found params.\n",
      " |      \n",
      " |      Only available if the underlying estimator implements\n",
      " |      ``inverse_transform`` and ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      Xt : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Result of the `inverse_transform` function for `Xt` based on the\n",
      " |          estimator with the best found parameters.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Call predict on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          The predicted labels or values for `X` based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Call predict_log_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_log_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class log-probabilities for `X` based on the estimator\n",
      " |          with the best found parameters. The order of the classes\n",
      " |          corresponds to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Call predict_proba on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``predict_proba``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Predicted class probabilities for `X` based on the estimator with\n",
      " |          the best found parameters. The order of the classes corresponds\n",
      " |          to that in the fitted attribute :term:`classes_`.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Return the score on the given data, if the estimator has been refit.\n",
      " |      \n",
      " |      This uses the score defined by ``scoring`` where provided, and the\n",
      " |      ``best_estimator_.score`` method otherwise.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      " |          Target relative to X for classification or regression;\n",
      " |          None for unsupervised learning.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          The score defined by ``scoring`` if provided, and the\n",
      " |          ``best_estimator_.score`` method otherwise.\n",
      " |  \n",
      " |  score_samples(self, X)\n",
      " |      Call score_samples on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if ``refit=True`` and the underlying estimator supports\n",
      " |      ``score_samples``.\n",
      " |      \n",
      " |      .. versionadded:: 0.24\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : iterable\n",
      " |          Data to predict on. Must fulfill input requirements\n",
      " |          of the underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_score : ndarray of shape (n_samples,)\n",
      " |          The ``best_estimator_.score_samples`` method.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Call transform on the estimator with the best found parameters.\n",
      " |      \n",
      " |      Only available if the underlying estimator supports ``transform`` and\n",
      " |      ``refit=True``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : indexable, length n_samples\n",
      " |          Must fulfill the input assumptions of the\n",
      " |          underlying estimator.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      " |          `X` transformed in the new space based on the estimator with\n",
      " |          the best found parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseSearchCV:\n",
      " |  \n",
      " |  classes_\n",
      " |      Class labels.\n",
      " |      \n",
      " |      Only available when `refit=True` and the estimator is a classifier.\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |      \n",
      " |      Only available when `refit=True`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LogisticRegression in module sklearn.linear_model._logistic:\n",
      "\n",
      "class LogisticRegression(sklearn.linear_model._base.LinearClassifierMixin, sklearn.linear_model._base.SparseCoefMixin, sklearn.base.BaseEstimator)\n",
      " |  LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |  \n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the\n",
      " |  cross-entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag', 'saga' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      " |  that regularization is applied by default**. It can handle both dense\n",
      " |  and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      " |  floats for optimal performance; any other input format will be converted\n",
      " |  (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation, or no regularization. The 'liblinear' solver\n",
      " |  supports both L1 and L2 regularization, with a dual formulation only for\n",
      " |  the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      " |  'saga' solver.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : {'l1', 'l2', 'elasticnet', 'none'}, default='l2'\n",
      " |      Specify the norm of the penalty:\n",
      " |  \n",
      " |      - `'none'`: no penalty is added;\n",
      " |      - `'l2'`: add a L2 penalty term and it is the default choice;\n",
      " |      - `'l1'`: add a L1 penalty term;\n",
      " |      - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      " |  \n",
      " |      .. warning::\n",
      " |         Some penalties may not work with some solvers. See the parameter\n",
      " |         `solver` below, to know the compatibility between the penalty and\n",
      " |         solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default=False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default=1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default=1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default=1\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      " |      data. See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  solver : {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      " |      To choose a solver, you might want to consider the following aspects:\n",
      " |  \n",
      " |          - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      " |            and 'saga' are faster for large ones;\n",
      " |          - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
      " |            'lbfgs' handle multinomial loss;\n",
      " |          - 'liblinear' is limited to one-versus-rest schemes.\n",
      " |  \n",
      " |      .. warning::\n",
      " |         The choice of the algorithm depends on the penalty chosen:\n",
      " |         Supported penalties by solver:\n",
      " |  \n",
      " |         - 'newton-cg'   -   ['l2', 'none']\n",
      " |         - 'lbfgs'       -   ['l2', 'none']\n",
      " |         - 'liblinear'   -   ['l1', 'l2']\n",
      " |         - 'sag'         -   ['l2', 'none']\n",
      " |         - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']\n",
      " |  \n",
      " |      .. note::\n",
      " |         'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |         features with approximately the same scale. You can\n",
      " |         preprocess the data with a scaler from :mod:`sklearn.preprocessing`.\n",
      " |  \n",
      " |      .. seealso::\n",
      " |         Refer to the User Guide for more information regarding\n",
      " |         :class:`LogisticRegression` and more specifically the\n",
      " |         `Table <https://scikit-learn.org/dev/modules/linear_model.html#logistic-regression>`_\n",
      " |         summarazing solver/penalty supports.\n",
      " |         <!--\n",
      " |         # noqa: E501\n",
      " |         -->\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default=100\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.22\n",
      " |          Default changed from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  l1_ratio : float, default=None\n",
      " |      The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      " |      used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      " |      to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      " |      to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      " |      combination of L1 and L2.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes, )\n",
      " |      A list of class labels known to the classifier.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SGDClassifier : Incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      " |      Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      " |      http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :])\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          Training vector, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,) default=None\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The SAGA solver supports both float64 and float32 bit arrays.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict logarithm of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Vector to be scored, where `n_samples` is the number of samples and\n",
      " |          `n_features` is the number of features.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is proportional to the signed\n",
      " |      distance of that sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data matrix for which we want to get the confidence scores.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      scores : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      " |          Confidence scores per `(n_samples, n_classes)` combination. In the\n",
      " |          binary case, confidence score for `self.classes_[1]` where >0 means\n",
      " |          this class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The data matrix for which we want to get the predictions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Vector containing the class labels for each sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter={'solver':['saga','newton-cg','liblinear'],'C':[1e-4,1e-3,1e-2,1e-1,1,2,3,10,100,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    model=GridSearchCV(SVC(random_state=42,max_iter=100),param_grid=parameter,cv=5)\n",
    "    model.fit(xtrain,ytrain)\n",
    "    best_estimator=model.best_params_\n",
    "    best_score=model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVC in module sklearn.svm._classes:\n",
      "\n",
      "class SVC(sklearn.svm._base.BaseSVC)\n",
      " |  SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |  \n",
      " |  C-Support Vector Classification.\n",
      " |  \n",
      " |  The implementation is based on libsvm. The fit time scales at least\n",
      " |  quadratically with the number of samples and may be impractical\n",
      " |  beyond tens of thousands of samples. For large datasets\n",
      " |  consider using :class:`~sklearn.svm.LinearSVC` or\n",
      " |  :class:`~sklearn.linear_model.SGDClassifier` instead, possibly after a\n",
      " |  :class:`~sklearn.kernel_approximation.Nystroem` transformer.\n",
      " |  \n",
      " |  The multiclass support is handled according to a one-vs-one scheme.\n",
      " |  \n",
      " |  For details on the precise mathematical formulation of the provided\n",
      " |  kernel functions and how `gamma`, `coef0` and `degree` affect each\n",
      " |  other, see the corresponding section in the narrative documentation:\n",
      " |  :ref:`svm_kernels`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  C : float, default=1.0\n",
      " |      Regularization parameter. The strength of the regularization is\n",
      " |      inversely proportional to C. Must be strictly positive. The penalty\n",
      " |      is a squared l2 penalty.\n",
      " |  \n",
      " |  kernel : {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'} or callable,          default='rbf'\n",
      " |      Specifies the kernel type to be used in the algorithm.\n",
      " |      If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |      used to pre-compute the kernel matrix from data matrices; that matrix\n",
      " |      should be an array of shape ``(n_samples, n_samples)``.\n",
      " |  \n",
      " |  degree : int, default=3\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : {'scale', 'auto'} or float, default='scale'\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      - if ``gamma='scale'`` (default) is passed then it uses\n",
      " |        1 / (n_features * X.var()) as value of gamma,\n",
      " |      - if 'auto', uses 1 / n_features.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``gamma`` changed from 'auto' to 'scale'.\n",
      " |  \n",
      " |  coef0 : float, default=0.0\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  shrinking : bool, default=True\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |      See the :ref:`User Guide <shrinking_svm>`.\n",
      " |  \n",
      " |  probability : bool, default=False\n",
      " |      Whether to enable probability estimates. This must be enabled prior\n",
      " |      to calling `fit`, will slow down that method as it internally uses\n",
      " |      5-fold cross-validation, and `predict_proba` may be inconsistent with\n",
      " |      `predict`. Read more in the :ref:`User Guide <scores_probabilities>`.\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  cache_size : float, default=200\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default=None\n",
      " |      Set the parameter C of class i to class_weight[i]*C for\n",
      " |      SVC. If not given, all classes are supposed to have\n",
      " |      weight one.\n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, default=-1\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  decision_function_shape : {'ovo', 'ovr'}, default='ovr'\n",
      " |      Whether to return a one-vs-rest ('ovr') decision function of shape\n",
      " |      (n_samples, n_classes) as all other classifiers, or the original\n",
      " |      one-vs-one ('ovo') decision function of libsvm which has shape\n",
      " |      (n_samples, n_classes * (n_classes - 1) / 2). However, one-vs-one\n",
      " |      ('ovo') is always used as multi-class strategy. The parameter is\n",
      " |      ignored for binary classification.\n",
      " |  \n",
      " |      .. versionchanged:: 0.19\n",
      " |          decision_function_shape is 'ovr' by default.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *decision_function_shape='ovr'* is recommended.\n",
      " |  \n",
      " |      .. versionchanged:: 0.17\n",
      " |         Deprecated *decision_function_shape='ovo' and None*.\n",
      " |  \n",
      " |  break_ties : bool, default=False\n",
      " |      If true, ``decision_function_shape='ovr'``, and number of classes > 2,\n",
      " |      :term:`predict` will break ties according to the confidence values of\n",
      " |      :term:`decision_function`; otherwise the first class among the tied\n",
      " |      classes is returned. Please note that breaking ties comes at a\n",
      " |      relatively high computational cost compared to a simple predict.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls the pseudo random number generation for shuffling the data for\n",
      " |      probability estimates. Ignored when `probability` is False.\n",
      " |      Pass an int for reproducible output across multiple function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_weight_ : ndarray of shape (n_classes,)\n",
      " |      Multipliers of parameter C for each class.\n",
      " |      Computed based on the ``class_weight`` parameter.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The classes labels.\n",
      " |  \n",
      " |  coef_ : ndarray of shape (n_classes * (n_classes - 1) / 2, n_features)\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is a readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  dual_coef_ : ndarray of shape (n_classes -1, n_SV)\n",
      " |      Dual coefficients of the support vector in the decision\n",
      " |      function (see :ref:`sgd_mathematical_formulation`), multiplied by\n",
      " |      their targets.\n",
      " |      For multiclass, coefficient for all 1-vs-1 classifiers.\n",
      " |      The layout of the coefficients in the multiclass case is somewhat\n",
      " |      non-trivial. See the :ref:`multi-class section of the User Guide\n",
      " |      <svm_multi_class>` for details.\n",
      " |  \n",
      " |  fit_status_ : int\n",
      " |      0 if correctly fitted, 1 otherwise (will raise warning)\n",
      " |  \n",
      " |  intercept_ : ndarray of shape (n_classes * (n_classes - 1) / 2,)\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  support_ : ndarray of shape (n_SV)\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : ndarray of shape (n_SV, n_features)\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  n_support_ : ndarray of shape (n_classes,), dtype=int32\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  probA_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |  probB_ : ndarray of shape (n_classes * (n_classes - 1) / 2)\n",
      " |      If `probability=True`, it corresponds to the parameters learned in\n",
      " |      Platt scaling to produce probability estimates from decision values.\n",
      " |      If `probability=False`, it's an empty array. Platt scaling uses the\n",
      " |      logistic function\n",
      " |      ``1 / (1 + exp(decision_value * probA_ + probB_))``\n",
      " |      where ``probA_`` and ``probB_`` are learned from the dataset [2]_. For\n",
      " |      more information on the multiclass case and training procedure see\n",
      " |      section 8 of [1]_.\n",
      " |  \n",
      " |  shape_fit_ : tuple of int of shape (n_dimensions_of_X,)\n",
      " |      Array dimensions of training vector ``X``.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  SVR : Support Vector Machine for Regression implemented using libsvm.\n",
      " |  \n",
      " |  LinearSVC : Scalable Linear Support Vector Machine for classification\n",
      " |      implemented using liblinear. Check the See Also section of\n",
      " |      LinearSVC for more comparison element.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] `LIBSVM: A Library for Support Vector Machines\n",
      " |      <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`_\n",
      " |  \n",
      " |  .. [2] `Platt, John (1999). \"Probabilistic outputs for support vector\n",
      " |      machines and comparison to regularizedlikelihood methods.\"\n",
      " |      <http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.1639>`_\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.pipeline import make_pipeline\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]])\n",
      " |  >>> y = np.array([1, 1, 2, 2])\n",
      " |  >>> from sklearn.svm import SVC\n",
      " |  >>> clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      " |                  ('svc', SVC(gamma='auto'))])\n",
      " |  \n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVC\n",
      " |      sklearn.svm._base.BaseSVC\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.svm._base.BaseLibSVM\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Evaluate the decision function for the samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The input samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : ndarray of shape (n_samples, n_classes * (n_classes-1) / 2)\n",
      " |          Returns the decision function of the sample for each class\n",
      " |          in the model.\n",
      " |          If decision_function_shape='ovr', the shape is (n_samples,\n",
      " |          n_classes).\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If decision_function_shape='ovo', the function values are proportional\n",
      " |      to the distance of the samples X to the separating hyperplane. If the\n",
      " |      exact distances are required, divide the function values by the norm of\n",
      " |      the weight vector (``coef_``). See also `this question\n",
      " |      <https://stats.stackexchange.com/questions/14876/\n",
      " |      interpreting-distance-from-hyperplane-in-svm>`_ for further details.\n",
      " |      If decision_function_shape='ovr', the decision function is a monotonic\n",
      " |      transformation of ovo decision function.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 or -1 is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : ndarray of shape (n_samples,)\n",
      " |          Class labels for samples in X.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Compute log probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features) or                 (n_samples_test, n_samples_train)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the log-probabilities of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Compute probabilities of possible outcomes for samples in X.\n",
      " |      \n",
      " |      The model need to have probability information computed at training\n",
      " |      time: fit with attribute `probability` set to True.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : ndarray of shape (n_samples, n_classes)\n",
      " |          Returns the probability of the sample for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute :term:`classes_`.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The probability model is created using cross validation, so\n",
      " |      the results can be slightly different than those obtained by\n",
      " |      predict. Also, it will produce meaningless results on very small\n",
      " |      datasets.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm._base.BaseSVC:\n",
      " |  \n",
      " |  probA_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  probB_\n",
      " |      Parameter learned in Platt scaling when `probability=True`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape  (n_classes * (n_classes - 1) / 2)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)                 or (n_samples, n_samples)\n",
      " |          Training vectors, where `n_samples` is the number of samples\n",
      " |          and `n_features` is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm._base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |      Weights assigned to the features when `kernel=\"linear\"`.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray of shape (n_features, n_classes)\n",
      " |  \n",
      " |  n_support_\n",
      " |      Number of support vectors for each class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter={'C':[1e-3,1e-2,1e-1,1,5,10,100]}\n",
    "help(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739021532743507"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    model=GridSearchCV(RandomForestClassifier(random_state=42,n_estimators=100),param_grid=parameter,cv=5)\n",
    "    model.fit(xtrain,ytrain)\n",
    "    best_estimator=model.best_params_\n",
    "    best_score=model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class RandomForestClassifier in module sklearn.ensemble._forest:\n",
      "\n",
      "class RandomForestClassifier(ForestClassifier)\n",
      " |  RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |  \n",
      " |  A random forest classifier.\n",
      " |  \n",
      " |  A random forest is a meta estimator that fits a number of decision tree\n",
      " |  classifiers on various sub-samples of the dataset and uses averaging to\n",
      " |  improve the predictive accuracy and control over-fitting.\n",
      " |  The sub-sample size is controlled with the `max_samples` parameter if\n",
      " |  `bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      " |  each tree.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <forest>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_estimators : int, default=100\n",
      " |      The number of trees in the forest.\n",
      " |  \n",
      " |      .. versionchanged:: 0.22\n",
      " |         The default value of ``n_estimators`` changed from 10 to 100\n",
      " |         in 0.22.\n",
      " |  \n",
      " |  criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |      Note: this parameter is tree-specific.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `round(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)` (same as \"auto\").\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  bootstrap : bool, default=True\n",
      " |      Whether bootstrap samples are used when building trees. If False, the\n",
      " |      whole dataset is used to build each tree.\n",
      " |  \n",
      " |  oob_score : bool, default=False\n",
      " |      Whether to use out-of-bag samples to estimate the generalization score.\n",
      " |      Only available if bootstrap=True.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      " |      :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      " |      trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors. See :term:`Glossary\n",
      " |      <n_jobs>` for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, default=None\n",
      " |      Controls both the randomness of the bootstrapping of the samples used\n",
      " |      when building trees (if ``bootstrap=True``) and the sampling of the\n",
      " |      features to consider when looking for the best split at each node\n",
      " |      (if ``max_features < n_features``).\n",
      " |      See :term:`Glossary <random_state>` for details.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      Controls the verbosity when fitting and predicting.\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just fit a whole\n",
      " |      new forest. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      " |      weights are computed based on the bootstrap sample for every tree\n",
      " |      grown.\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  max_samples : int or float, default=None\n",
      " |      If bootstrap is True, the number of samples to draw from X\n",
      " |      to train each base estimator.\n",
      " |  \n",
      " |      - If None (default), then draw `X.shape[0]` samples.\n",
      " |      - If int, then draw `max_samples` samples.\n",
      " |      - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      " |        `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  base_estimator_ : DecisionTreeClassifier\n",
      " |      The child estimator template used to create the collection of fitted\n",
      " |      sub-estimators.\n",
      " |  \n",
      " |  estimators_ : list of DecisionTreeClassifier\n",
      " |      The collection of fitted sub-estimators.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      " |      The classes labels (single output problem), or a list of arrays of\n",
      " |      class labels (multi-output problem).\n",
      " |  \n",
      " |  n_classes_ : int or list\n",
      " |      The number of classes (single output problem), or a list containing the\n",
      " |      number of classes for each output (multi-output problem).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |      .. deprecated:: 1.0\n",
      " |          Attribute `n_features_` was deprecated in version 1.0 and will be\n",
      " |          removed in 1.2. Use `n_features_in_` instead.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The impurity-based feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |  \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |  \n",
      " |  oob_score_ : float\n",
      " |      Score of the training dataset obtained using an out-of-bag estimate.\n",
      " |      This attribute exists only when ``oob_score`` is True.\n",
      " |  \n",
      " |  oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
      " |      Decision function computed with out-of-bag estimate on the training\n",
      " |      set. If n_estimators is small it might be possible that a data point\n",
      " |      was never left out during the bootstrap. In this case,\n",
      " |      `oob_decision_function_` might contain NaN. This attribute exists\n",
      " |      only when ``oob_score`` is True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      " |  sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
      " |      tree classifiers.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data,\n",
      " |  ``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      " |  of the criterion is identical for several splits enumerated during the\n",
      " |  search of the best split. To obtain a deterministic behaviour during\n",
      " |  fitting, ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.ensemble import RandomForestClassifier\n",
      " |  >>> from sklearn.datasets import make_classification\n",
      " |  >>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      " |  ...                            n_informative=2, n_redundant=0,\n",
      " |  ...                            random_state=0, shuffle=False)\n",
      " |  >>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  RandomForestClassifier(...)\n",
      " |  >>> print(clf.predict([[0, 0, 0, 0]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      RandomForestClassifier\n",
      " |      ForestClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseForest\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.ensemble._base.BaseEnsemble\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from ForestClassifier:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      The predicted class of an input sample is a vote by the trees in\n",
      " |      the forest, weighted by their probability estimates. That is,\n",
      " |      the predicted class is the one with highest mean probability\n",
      " |      estimate across the trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      The predicted class log-probabilities of an input sample is computed as\n",
      " |      the log of the mean predicted class probabilities of the trees in the\n",
      " |      forest.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      The predicted class probabilities of an input sample are computed as\n",
      " |      the mean predicted class probabilities of the trees in the forest.\n",
      " |      The class probability of a single tree is the fraction of samples of\n",
      " |      the same class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_samples, n_classes), or a list of such arrays\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseForest:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the forest to X, return leaf indices.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : ndarray of shape (n_samples, n_estimators)\n",
      " |          For each datapoint x in X and for each tree in the forest,\n",
      " |          return the index of the leaf x ends up in.\n",
      " |  \n",
      " |  decision_path(self, X)\n",
      " |      Return the decision path in the forest.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator matrix where non zero elements indicates\n",
      " |          that the samples goes through the nodes. The matrix is of CSR\n",
      " |          format.\n",
      " |      \n",
      " |      n_nodes_ptr : ndarray of shape (n_estimators + 1,)\n",
      " |          The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]\n",
      " |          gives the indicator value for the i-th estimator.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Build a forest of trees from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, its dtype will be converted\n",
      " |          to ``dtype=np.float32``. If a sparse matrix is provided, it will be\n",
      " |          converted into a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels in classification, real numbers in\n",
      " |          regression).\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseForest:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      The impurity-based feature importances.\n",
      " |      \n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance.\n",
      " |      \n",
      " |      Warning: impurity-based feature importances can be misleading for\n",
      " |      high cardinality features (many unique values). See\n",
      " |      :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  n_features_\n",
      " |      DEPRECATED: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      " |      \n",
      " |      Number of features when fitting the estimator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Return the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Return iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Return the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.ensemble._base.BaseEnsemble:\n",
      " |  \n",
      " |  __annotations__ = {'_required_parameters': typing.List[str]}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter={'max_depth':[5,10,15,20]}\n",
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9832285115303984"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(v,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=20, random_state=42)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:28:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:28:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:29:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:30:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:31:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:32:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:33:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:33:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:34:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:35:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:36:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:37:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:38:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:39:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[23:40:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v=len(input_features['clusters'].unique())\n",
    "for i in range(v):\n",
    "    dataframe=input_features[input_features['clusters']==i]\n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    model=GridSearchCV(XGBClassifier(random_state=42,max_iter=100),param_grid=parameter,cv=5)\n",
    "    ytrain_mapped = [1 if label == 1 else 0 for label in ytrain]\n",
    "    ytest_mapped = [1 if label == 1 else 0 for label in ytest]\n",
    "    model.fit(xtrain,ytrain_mapped)\n",
    "    best_estimator=model.best_params_\n",
    "    best_score=model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class XGBClassifier in module xgboost.sklearn:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  XGBClassifier(*, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: bool = False, **kwargs: Any) -> None\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |      n_estimators : int\n",
      " |          Number of boosting rounds.\n",
      " |  \n",
      " |      max_depth :  Optional[int]\n",
      " |          Maximum tree depth for base learners.\n",
      " |      max_leaves :\n",
      " |          Maximum number of leaves; 0 indicates no limit.\n",
      " |      max_bin :\n",
      " |          If using histogram-based algorithm, maximum number of bins per feature\n",
      " |      grow_policy :\n",
      " |          Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow\n",
      " |          depth-wise. 1: favor splitting at nodes with highest loss change.\n",
      " |      learning_rate : Optional[float]\n",
      " |          Boosting learning rate (xgb's \"eta\")\n",
      " |      verbosity : Optional[int]\n",
      " |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      " |      objective : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      " |          Specify the learning task and the corresponding learning objective or\n",
      " |          a custom objective function to be used (see note below).\n",
      " |      booster: Optional[str]\n",
      " |          Specify which booster to use: gbtree, gblinear or dart.\n",
      " |      tree_method: Optional[str]\n",
      " |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      " |          default, XGBoost will choose the most conservative option available.  It's\n",
      " |          recommended to study this option from the parameters document :doc:`tree method\n",
      " |          </treemethod>`\n",
      " |      n_jobs : Optional[int]\n",
      " |          Number of parallel threads used to run xgboost.  When used with other Scikit-Learn\n",
      " |          algorithms like grid search, you may choose which algorithm to parallelize and\n",
      " |          balance the threads.  Creating thread contention will significantly slow down both\n",
      " |          algorithms.\n",
      " |      gamma : Optional[float]\n",
      " |          (min_split_loss) Minimum loss reduction required to make a further partition on a\n",
      " |          leaf node of the tree.\n",
      " |      min_child_weight : Optional[float]\n",
      " |          Minimum sum of instance weight(hessian) needed in a child.\n",
      " |      max_delta_step : Optional[float]\n",
      " |          Maximum delta step we allow each tree's weight estimation to be.\n",
      " |      subsample : Optional[float]\n",
      " |          Subsample ratio of the training instance.\n",
      " |      sampling_method :\n",
      " |          Sampling method. Used only by `gpu_hist` tree method.\n",
      " |            - `uniform`: select random training instances uniformly.\n",
      " |            - `gradient_based` select random training instances with higher probability when\n",
      " |              the gradient and hessian are larger. (cf. CatBoost)\n",
      " |      colsample_bytree : Optional[float]\n",
      " |          Subsample ratio of columns when constructing each tree.\n",
      " |      colsample_bylevel : Optional[float]\n",
      " |          Subsample ratio of columns for each level.\n",
      " |      colsample_bynode : Optional[float]\n",
      " |          Subsample ratio of columns for each split.\n",
      " |      reg_alpha : Optional[float]\n",
      " |          L1 regularization term on weights (xgb's alpha).\n",
      " |      reg_lambda : Optional[float]\n",
      " |          L2 regularization term on weights (xgb's lambda).\n",
      " |      scale_pos_weight : Optional[float]\n",
      " |          Balancing of positive and negative weights.\n",
      " |      base_score : Optional[float]\n",
      " |          The initial prediction score of all instances, global bias.\n",
      " |      random_state : Optional[Union[numpy.random.RandomState, int]]\n",
      " |          Random number seed.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      " |             it uses Hogwild algorithm.\n",
      " |  \n",
      " |      missing : float, default np.nan\n",
      " |          Value in the data which needs to be present as a missing value.\n",
      " |      num_parallel_tree: Optional[int]\n",
      " |          Used for boosting random forest.\n",
      " |      monotone_constraints : Optional[Union[Dict[str, int], str]]\n",
      " |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      " |          for more information.\n",
      " |      interaction_constraints : Optional[Union[str, List[Tuple[str]]]]\n",
      " |          Constraints for interaction representing permitted interactions.  The\n",
      " |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      " |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      " |          allowed to interact with each other.  See :doc:`tutorial\n",
      " |          </tutorials/feature_interaction_constraint>` for more information\n",
      " |      importance_type: Optional[str]\n",
      " |          The feature importance type for the feature_importances\\_ property:\n",
      " |  \n",
      " |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      " |            \"total_cover\".\n",
      " |          * For linear model, only \"weight\" is defined and it's the normalized coefficients\n",
      " |            without bias.\n",
      " |  \n",
      " |      gpu_id : Optional[int]\n",
      " |          Device ordinal.\n",
      " |      validate_parameters : Optional[bool]\n",
      " |          Give warnings for unknown parameter.\n",
      " |      predictor : Optional[str]\n",
      " |          Force XGBoost to use specific predictor, available choices are [cpu_predictor,\n",
      " |          gpu_predictor].\n",
      " |      enable_categorical : bool\n",
      " |  \n",
      " |          .. versionadded:: 1.5.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame\n",
      " |          should be used to specify categorical data type.  Also, JSON/UBJSON\n",
      " |          serialization format is required.\n",
      " |  \n",
      " |      max_cat_to_onehot : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      " |          for categorical data.  When number of categories is lesser than the threshold\n",
      " |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      " |          into children nodes.  Only relevant for regression and binary classification.\n",
      " |          See :doc:`Categorical Data </tutorials/categorical>` for details.\n",
      " |  \n",
      " |      eval_metric : Optional[Union[str, List[str], Callable]]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      " |          string or list of strings as names of predefined metric in XGBoost (See\n",
      " |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any other\n",
      " |          user defined metric that looks like `sklearn.metrics`.\n",
      " |  \n",
      " |          If custom objective is also provided, then custom metric should implement the\n",
      " |          corresponding reverse link function.\n",
      " |  \n",
      " |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      " |          object is provided, it's assumed to be a cost function and by default XGBoost will\n",
      " |          minimize the result during early stopping.\n",
      " |  \n",
      " |          For advanced usage on Early stopping like directly choosing to maximize instead of\n",
      " |          minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      " |  \n",
      " |          See :doc:`Custom Objective and Evaluation Metric </tutorials/custom_metric_obj>`\n",
      " |          for more.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |               This parameter replaces `eval_metric` in :py:meth:`fit` method.  The old one\n",
      " |               receives un-transformed prediction regardless of whether custom objective is\n",
      " |               being used.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              from sklearn.datasets import load_diabetes\n",
      " |              from sklearn.metrics import mean_absolute_error\n",
      " |              X, y = load_diabetes(return_X_y=True)\n",
      " |              reg = xgb.XGBRegressor(\n",
      " |                  tree_method=\"hist\",\n",
      " |                  eval_metric=mean_absolute_error,\n",
      " |              )\n",
      " |              reg.fit(X, y, eval_set=[(X, y)])\n",
      " |  \n",
      " |      early_stopping_rounds : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Activates early stopping. Validation metric needs to improve at least once in\n",
      " |          every **early_stopping_rounds** round(s) to continue training.  Requires at least\n",
      " |          one item in **eval_set** in :py:meth:`fit`.\n",
      " |  \n",
      " |          The method returns the model from the last iteration (not the best one).  If\n",
      " |          there's more than one item in **eval_set**, the last entry will be used for early\n",
      " |          stopping.  If there's more than one metric in **eval_metric**, the last metric\n",
      " |          will be used for early stopping.\n",
      " |  \n",
      " |          If early stopping occurs, the model will have three additional fields:\n",
      " |          :py:attr:`best_score`, :py:attr:`best_iteration` and\n",
      " |          :py:attr:`best_ntree_limit`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |              This parameter replaces `early_stopping_rounds` in :py:meth:`fit` method.\n",
      " |  \n",
      " |      callbacks : Optional[List[TrainingCallback]]\n",
      " |          List of callback functions that are applied at end of each iteration.\n",
      " |          It is possible to use predefined callbacks by using\n",
      " |          :ref:`Callback API <callback_api>`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             States in callback are not preserved during training, which means callback\n",
      " |             objects can not be reused for multiple training sessions without\n",
      " |             reinitialization or deepcopy.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              for params in parameters_grid:\n",
      " |                  # be sure to (re)initialize the callbacks before each run\n",
      " |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      " |                  xgboost.train(params, Xy, callbacks=callbacks)\n",
      " |  \n",
      " |      kwargs : dict, optional\n",
      " |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      " |          can be found :doc:`here </parameter>`.\n",
      " |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      " |          dict simultaneously will result in a TypeError.\n",
      " |  \n",
      " |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      " |  \n",
      " |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      " |              that parameters passed via this argument will interact properly\n",
      " |              with scikit-learn.\n",
      " |  \n",
      " |          .. note::  Custom objective function\n",
      " |  \n",
      " |              A custom objective function can be provided for the ``objective``\n",
      " |              parameter. In this case, it should have the signature\n",
      " |              ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |              y_true: array_like of shape [n_samples]\n",
      " |                  The target values\n",
      " |              y_pred: array_like of shape [n_samples]\n",
      " |                  The predicted values\n",
      " |  \n",
      " |              grad: array_like of shape [n_samples]\n",
      " |                  The value of the gradient for each sample point.\n",
      " |              hess: array_like of shape [n_samples]\n",
      " |                  The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: bool = False, **kwargs: Any) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X: Any, y: Any, *, sample_weight: Union[Any, NoneType] = None, base_margin: Union[Any, NoneType] = None, eval_set: Union[Sequence[Tuple[Any, Any]], NoneType] = None, eval_metric: Union[str, Sequence[str], Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None, early_stopping_rounds: Union[int, NoneType] = None, verbose: Union[bool, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Union[Sequence[Any], NoneType] = None, base_margin_eval_set: Union[Sequence[Any], NoneType] = None, feature_weights: Union[Any, NoneType] = None, callbacks: Union[Sequence[xgboost.callback.TrainingCallback], NoneType] = None) -> 'XGBClassifier'\n",
      " |      Fit gradient boosting classifier.\n",
      " |      \n",
      " |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      " |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      " |      pass ``xgb_model`` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Feature matrix\n",
      " |      y :\n",
      " |          Labels\n",
      " |      sample_weight :\n",
      " |          instance weights\n",
      " |      base_margin :\n",
      " |          global bias for each instance.\n",
      " |      eval_set :\n",
      " |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      " |          metrics will be computed.\n",
      " |          Validation metrics will help us track the performance of the model.\n",
      " |      \n",
      " |      eval_metric : str, list of str, or callable, optional\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `eval_metric` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |      \n",
      " |      early_stopping_rounds : int\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `early_stopping_rounds` in :py:meth:`__init__` or\n",
      " |              :py:meth:`set_params` instead.\n",
      " |      verbose :\n",
      " |          If `verbose` and an evaluation set is used, writes the evaluation metric\n",
      " |          measured on the validation set to stderr.\n",
      " |      xgb_model :\n",
      " |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |      sample_weight_eval_set :\n",
      " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      " |          object storing instance weights for the i-th validation set.\n",
      " |      base_margin_eval_set :\n",
      " |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      " |          object storing base margin for the i-th validation set.\n",
      " |      feature_weights :\n",
      " |          Weight for each feature, defines the probability of each feature being\n",
      " |          selected when colsample is being used.  All values must be greater than 0,\n",
      " |          otherwise a `ValueError` is thrown.\n",
      " |      \n",
      " |      callbacks :\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `callbacks` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |  \n",
      " |  predict(self, X: Any, output_margin: bool = False, ntree_limit: Union[int, NoneType] = None, validate_features: bool = True, base_margin: Union[Any, NoneType] = None, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Predict with `X`.  If the model is trained with early stopping, then `best_iteration`\n",
      " |      is used automatically.  For tree models, when data is on GPU, like cupy array or\n",
      " |      cuDF dataframe and `predictor` is not specified, the prediction is run on GPU\n",
      " |      automatically, otherwise it will run on CPU.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Data to predict with.\n",
      " |      output_margin :\n",
      " |          Whether to output the raw untransformed margin value.\n",
      " |      ntree_limit :\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features :\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin :\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      " |          20)``, then only the forests built during [10, 20) (half open set) rounds are\n",
      " |          used in this prediction.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction\n",
      " |  \n",
      " |  predict_proba(self, X: Any, ntree_limit: Union[int, NoneType] = None, validate_features: bool = True, base_margin: Union[Any, NoneType] = None, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Predict the probability of each `X` example being of a given class.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix.\n",
      " |      ntree_limit : int\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin : array_like\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      " |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      " |          used in this prediction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      " |          probability of each data example being of a given class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __sklearn_is_fitted__(self) -> bool\n",
      " |  \n",
      " |  apply(self, X: Any, ntree_limit: int = 0, iteration_range: Union[Tuple[int, int], NoneType] = None) -> numpy.ndarray\n",
      " |      Return the predicted leaf every tree for each sample. If the model is trained with\n",
      " |      early stopping, then `best_iteration` is used automatically.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      iteration_range :\n",
      " |          See :py:meth:`predict`.\n",
      " |      \n",
      " |      ntree_limit :\n",
      " |          Deprecated, use ``iteration_range`` instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      " |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      " |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      " |      function.\n",
      " |      \n",
      " |      The returned evaluation result is a dictionary:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result\n",
      " |  \n",
      " |  get_booster(self) -> xgboost.core.Booster\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_num_boosting_rounds(self) -> int\n",
      " |      Gets the number of xgboost boosting rounds.\n",
      " |  \n",
      " |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self) -> Dict[str, Any]\n",
      " |      Get xgboost specific parameters.\n",
      " |  \n",
      " |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      " |      Load the model from a file or bytearray. Path to file can be local\n",
      " |      or as an URI.\n",
      " |      \n",
      " |      The model is loaded from XGBoost format which is universal among the various\n",
      " |      XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as\n",
      " |      feature_names) will not be loaded when using binary format.  To save those\n",
      " |      attributes, use JSON/UBJ instead.  See :doc:`Model IO </tutorials/saving_model>`\n",
      " |      for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.load_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.load_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname :\n",
      " |          Input file name or memory buffer(see also save_raw)\n",
      " |  \n",
      " |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      The model is saved in an XGBoost internal format which is universal among the\n",
      " |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      " |      (such as feature_names) will not be saved when using binary format.  To save\n",
      " |      those attributes, use JSON/UBJ instead. See :doc:`Model IO\n",
      " |      </tutorials/saving_model>` for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.save_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.save_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or os.PathLike\n",
      " |          Output file name\n",
      " |  \n",
      " |  set_params(self, **params: Any) -> 'XGBModel'\n",
      " |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      " |      allow unknown kwargs. This allows using the full range of xgboost\n",
      " |      parameters that are not defined as member variables in sklearn grid\n",
      " |      search.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from XGBModel:\n",
      " |  \n",
      " |  best_iteration\n",
      " |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      " |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      " |  \n",
      " |  best_ntree_limit\n",
      " |  \n",
      " |  best_score\n",
      " |      The best score obtained by early stopping.\n",
      " |  \n",
      " |  coef_\n",
      " |      Coefficients property\n",
      " |      \n",
      " |      .. note:: Coefficients are defined only for linear learners\n",
      " |      \n",
      " |          Coefficients are only defined when the linear model is chosen as\n",
      " |          base learner (`booster=gblinear`). It is not defined for other base\n",
      " |          learner types, such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Feature importances property, return depends on `importance_type` parameter.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      " |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      " |  \n",
      " |  feature_names_in_\n",
      " |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has feature\n",
      " |      names that are all strings.\n",
      " |  \n",
      " |  intercept_\n",
      " |      Intercept (bias) property\n",
      " |      \n",
      " |      .. note:: Intercept is defined only for linear learners\n",
      " |      \n",
      " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types,\n",
      " |          such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :py:meth:`fit`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter={'learning_rate':[1e-4,1e-3,1e-2,1e-1,1,5,10,100],'max_depth':[1,3,5,10,20,40,50]}\n",
    "help(XGBClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=model.predict(xtest)\n",
    "accuracy_score(ytest_mapped,v)\n",
    "best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('data_ingestion/input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>clusters</th>\n",
       "      <th>output_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.031900</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.126600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.229600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.729700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.498300</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.192700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.732800</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.501533</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.368433</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.949300</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.498100</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.649100</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.809800</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  405 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0      3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1      2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2      2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3      2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4      3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556    1.4794   \n",
       "3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689    1.5322   \n",
       "3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022    1.4945   \n",
       "3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800    1.5680   \n",
       "3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567    1.4920   \n",
       "\n",
       "      Sensor-10  Sensor-11  Sensor-12  ...  Sensor-581  Sensor-583  \\\n",
       "0        0.0089     0.0052     0.9655  ...    0.009000    0.501600   \n",
       "1        0.0119    -0.0082     0.9572  ...    0.008100    0.495300   \n",
       "2       -0.0143     0.0017     0.9702  ...    0.007333    0.495800   \n",
       "3       -0.0534    -0.0284     0.9708  ...    0.004733    0.496200   \n",
       "4       -0.0078    -0.0005     0.9680  ...    0.005867    0.498300   \n",
       "...         ...        ...        ...  ...         ...         ...   \n",
       "3069    -0.0198    -0.0004     0.9535  ...    0.002400    0.508000   \n",
       "3070     0.0205    -0.0213     0.9561  ...    0.005700    0.501533   \n",
       "3071     0.0247    -0.0049     0.9560  ...    0.004400    0.498600   \n",
       "3072     0.0009     0.0094     0.9560  ...    0.006233    0.498100   \n",
       "3073    -0.0095     0.0165     0.9525  ...    0.005333    0.497500   \n",
       "\n",
       "      Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n",
       "0         0.0152      0.0040    3.031900      0.0465      0.0299      0.0090   \n",
       "1         0.0105      0.0037    2.126600     -0.0012      0.0252      0.0081   \n",
       "2         0.0111      0.0033    2.229600     -0.0012      0.0252      0.0081   \n",
       "3         0.0086      0.0024    1.729700     -0.0012      0.0252      0.0081   \n",
       "4         0.0159      0.0041    3.192700     -0.0012      0.0252      0.0081   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069      0.0139      0.0039    2.732800      0.0234      0.0073      0.0024   \n",
       "3070      0.0169      0.0040    3.368433      0.0234      0.0073      0.0024   \n",
       "3071      0.0147      0.0038    2.949300      0.0142      0.0156      0.0044   \n",
       "3072      0.0132      0.0035    2.649100      0.0142      0.0156      0.0044   \n",
       "3073      0.0140      0.0036    2.809800      0.0142      0.0156      0.0044   \n",
       "\n",
       "      clusters  output_feature  \n",
       "0            0            -1.0  \n",
       "1            0            -1.0  \n",
       "2            3            -1.0  \n",
       "3            0            -1.0  \n",
       "4            1            -1.0  \n",
       "...        ...             ...  \n",
       "3069         3            -1.0  \n",
       "3070         0            -1.0  \n",
       "3071         3            -1.0  \n",
       "3072         1            -1.0  \n",
       "3073         0            -1.0  \n",
       "\n",
       "[3074 rows x 405 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataframe.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-579</th>\n",
       "      <th>Sensor-580</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.031900</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.126600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.229600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028033</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.729700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.498300</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.192700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3069</td>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.732800</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>3070</td>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.501533</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.368433</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3071</td>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.949300</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3072</td>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.498100</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.649100</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3073</td>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.809800</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  \\\n",
       "0              0   3076.81   2158.75  2208.2334    1.0980     100.0  110.1900   \n",
       "1              1   2951.62   2511.92  2253.5111    0.9660     100.0  109.7611   \n",
       "2              2   2930.42   2505.17  2235.0556    1.6347     100.0  109.9856   \n",
       "3              3   2997.28   2357.99  2141.0667    0.9698     100.0   98.3344   \n",
       "4              4   3025.10   2475.18  2235.0556    1.6347     100.0  109.9856   \n",
       "...          ...       ...       ...        ...       ...       ...       ...   \n",
       "3069        3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556   \n",
       "3070        3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689   \n",
       "3071        3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022   \n",
       "3072        3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800   \n",
       "3073        3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567   \n",
       "\n",
       "      Sensor-9  Sensor-10  Sensor-11  ...  Sensor-579  Sensor-580  Sensor-581  \\\n",
       "0       1.4357     0.0089     0.0052  ...    0.046500    0.029900    0.009000   \n",
       "1       1.5527     0.0119    -0.0082  ...   -0.001200    0.025200    0.008100   \n",
       "2       1.4588    -0.0143     0.0017  ...    0.027600    0.020000    0.007333   \n",
       "3       1.5973    -0.0534    -0.0284  ...    0.028033    0.013267    0.004733   \n",
       "4       1.5525    -0.0078    -0.0005  ...    0.027500    0.018433    0.005867   \n",
       "...        ...        ...        ...  ...         ...         ...         ...   \n",
       "3069    1.4794    -0.0198    -0.0004  ...    0.023400    0.007300    0.002400   \n",
       "3070    1.5322     0.0205    -0.0213  ...    0.017433    0.014833    0.005700   \n",
       "3071    1.4945     0.0247    -0.0049  ...    0.014200    0.015600    0.004400   \n",
       "3072    1.5680     0.0009     0.0094  ...    0.027000    0.020033    0.006233   \n",
       "3073    1.4920    -0.0095     0.0165  ...    0.027567    0.016700    0.005333   \n",
       "\n",
       "      Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  \\\n",
       "0       0.501600      0.0152      0.0040    3.031900      0.0465      0.0299   \n",
       "1       0.495300      0.0105      0.0037    2.126600     -0.0012      0.0252   \n",
       "2       0.495800      0.0111      0.0033    2.229600     -0.0012      0.0252   \n",
       "3       0.496200      0.0086      0.0024    1.729700     -0.0012      0.0252   \n",
       "4       0.498300      0.0159      0.0041    3.192700     -0.0012      0.0252   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069    0.508000      0.0139      0.0039    2.732800      0.0234      0.0073   \n",
       "3070    0.501533      0.0169      0.0040    3.368433      0.0234      0.0073   \n",
       "3071    0.498600      0.0147      0.0038    2.949300      0.0142      0.0156   \n",
       "3072    0.498100      0.0132      0.0035    2.649100      0.0142      0.0156   \n",
       "3073    0.497500      0.0140      0.0036    2.809800      0.0142      0.0156   \n",
       "\n",
       "      Sensor-589  \n",
       "0         0.0090  \n",
       "1         0.0081  \n",
       "2         0.0081  \n",
       "3         0.0081  \n",
       "4         0.0081  \n",
       "...          ...  \n",
       "3069      0.0024  \n",
       "3070      0.0024  \n",
       "3071      0.0044  \n",
       "3072      0.0044  \n",
       "3073      0.0044  \n",
       "\n",
       "[3074 rows x 404 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\utils\\optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, random_state=42, solver='newton-cg')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.read_csv('data_ingestion/input.csv')\n",
    "dataframe.drop(['Unnamed: 0'],axis=1,inplace=True)               \n",
    "X=dataframe.iloc[:,:-2]\n",
    "Y=dataframe.iloc[:,-1]\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "parameter={'solver':['newton-cg'],'C':[1e-3,1e-2,1e-1,1,3,10]}\n",
    "model=GridSearchCV(LogisticRegression(random_state=42,max_iter=100),param_grid=parameter,cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "best_estimator=model.best_params_\n",
    "solver=best_estimator['solver']\n",
    "C=best_estimator['C']\n",
    "model1=LogisticRegression(random_state=42,max_iter=100,solver=solver,C=C)\n",
    "model1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=model1.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -1.0\n",
       "1      -1.0\n",
       "2      -1.0\n",
       "3      -1.0\n",
       "4      -1.0\n",
       "       ... \n",
       "3069   -1.0\n",
       "3070   -1.0\n",
       "3071   -1.0\n",
       "3072   -1.0\n",
       "3073   -1.0\n",
       "Name: output_feature, Length: 3074, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9469122426868906"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(v,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=10, max_iter=100, random_state=42)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.read_csv('data_ingestion/input.csv')\n",
    "dataframe.drop(['Unnamed: 0'],axis=1,inplace=True)               \n",
    "X=dataframe.iloc[:,:-2]\n",
    "Y=dataframe.iloc[:,-1]\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "parameter={'C':[1e-3,1e-2,1e-1,1,5,10,100]}\n",
    "model=GridSearchCV(SVC(random_state=42,max_iter=100),param_grid=parameter,cv=5)\n",
    "model.fit(xtrain,ytrain)\n",
    "best_estimator=model.best_params_\n",
    "C=best_estimator['C']\n",
    "model1=SVC(random_state=42,max_iter=100,C=C)\n",
    "model1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=model1.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10292524377031419"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(v,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13249651324965134"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=model1.predict(xtrain)\n",
    "accuracy_score(v,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-579</th>\n",
       "      <th>Sensor-580</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.031900</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.495300</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.126600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.495800</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.229600</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028033</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.496200</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.729700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.498300</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.192700</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.732800</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.501533</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.368433</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.949300</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.498100</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.649100</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.497500</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.809800</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0      3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1      2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2      2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3      2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4      3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556    1.4794   \n",
       "3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689    1.5322   \n",
       "3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022    1.4945   \n",
       "3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800    1.5680   \n",
       "3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567    1.4920   \n",
       "\n",
       "      Sensor-10  Sensor-11  Sensor-12  ...  Sensor-579  Sensor-580  \\\n",
       "0        0.0089     0.0052     0.9655  ...    0.046500    0.029900   \n",
       "1        0.0119    -0.0082     0.9572  ...   -0.001200    0.025200   \n",
       "2       -0.0143     0.0017     0.9702  ...    0.027600    0.020000   \n",
       "3       -0.0534    -0.0284     0.9708  ...    0.028033    0.013267   \n",
       "4       -0.0078    -0.0005     0.9680  ...    0.027500    0.018433   \n",
       "...         ...        ...        ...  ...         ...         ...   \n",
       "3069    -0.0198    -0.0004     0.9535  ...    0.023400    0.007300   \n",
       "3070     0.0205    -0.0213     0.9561  ...    0.017433    0.014833   \n",
       "3071     0.0247    -0.0049     0.9560  ...    0.014200    0.015600   \n",
       "3072     0.0009     0.0094     0.9560  ...    0.027000    0.020033   \n",
       "3073    -0.0095     0.0165     0.9525  ...    0.027567    0.016700   \n",
       "\n",
       "      Sensor-581  Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  \\\n",
       "0       0.009000    0.501600      0.0152      0.0040    3.031900      0.0465   \n",
       "1       0.008100    0.495300      0.0105      0.0037    2.126600     -0.0012   \n",
       "2       0.007333    0.495800      0.0111      0.0033    2.229600     -0.0012   \n",
       "3       0.004733    0.496200      0.0086      0.0024    1.729700     -0.0012   \n",
       "4       0.005867    0.498300      0.0159      0.0041    3.192700     -0.0012   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069    0.002400    0.508000      0.0139      0.0039    2.732800      0.0234   \n",
       "3070    0.005700    0.501533      0.0169      0.0040    3.368433      0.0234   \n",
       "3071    0.004400    0.498600      0.0147      0.0038    2.949300      0.0142   \n",
       "3072    0.006233    0.498100      0.0132      0.0035    2.649100      0.0142   \n",
       "3073    0.005333    0.497500      0.0140      0.0036    2.809800      0.0142   \n",
       "\n",
       "      Sensor-588  Sensor-589  \n",
       "0         0.0299      0.0090  \n",
       "1         0.0252      0.0081  \n",
       "2         0.0252      0.0081  \n",
       "3         0.0252      0.0081  \n",
       "4         0.0252      0.0081  \n",
       "...          ...         ...  \n",
       "3069      0.0073      0.0024  \n",
       "3070      0.0073      0.0024  \n",
       "3071      0.0156      0.0044  \n",
       "3072      0.0156      0.0044  \n",
       "3073      0.0156      0.0044  \n",
       "\n",
       "[3074 rows x 403 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check():\n",
    "    dataframe=pd.read_csv('data_ingestion/input.csv')\n",
    "    dataframe.drop(['Unnamed: 0'],axis=1,inplace=True)               \n",
    "    X=dataframe.iloc[:,:-2]\n",
    "    Y=dataframe.iloc[:,-1]\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "    parameter={'max_depth':[5,10,15,20]}\n",
    "    model=GridSearchCV(RandomForestClassifier(random_state=42,n_estimators=100),param_grid=parameter,cv=5)\n",
    "    model.fit(xtrain,ytrain)\n",
    "    best_estimator=model.best_params_\n",
    "    max_depth=best_estimator['max_depth']\n",
    "    model1=RandomForestClassifier(random_state=42,n_estimators=100,max_depth=max_depth)\n",
    "    model1.fit(xtrain,ytrain)\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9772481040086674"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=model1.predict(xtest)\n",
    "accuracy_score(ytest,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99488609948861"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=model1.predict(xtrain)\n",
    "accuracy_score(ytrain,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:41:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:41:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:41:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:41:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:41:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:41:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:41:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:42:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:39] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:43:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:44:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:09] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:19] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:32] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:45:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[21:46:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"max_iter\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_iter=100, max_leaves=0,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=42, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe=pd.read_csv('data_ingestion/input.csv')\n",
    "dataframe.drop(['Unnamed: 0'],axis=1,inplace=True)               \n",
    "X=dataframe.iloc[:,:-2]\n",
    "Y=dataframe.iloc[:,-1]\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=.3,random_state=42)\n",
    "ytrain_mapped = [1 if label == 1 else 0 for label in ytrain]\n",
    "ytest_mapped = [1 if label == 1 else 0 for label in ytest]\n",
    "parameter={'learning_rate':[1e-3,1e-2,1e-1,1,5],'max_depth':[1,3,5,10]}\n",
    "model=GridSearchCV(XGBClassifier(random_state=42,max_iter=100),param_grid=parameter,cv=5)\n",
    "model.fit(xtrain,ytrain_mapped)\n",
    "best_estimator=model.best_params_\n",
    "learning_rate=best_estimator['learning_rate']\n",
    "max_depth=best_estimator['max_depth']\n",
    "model1=XGBClassifier(random_state=42,max_iter=100,max_depth=max_depth,learning_rate=learning_rate)\n",
    "model1.fit(xtrain,ytrain_mapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17596\\2309534492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytest_mapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "v=model1.predict(xtest)\n",
    "accuracy_score(v,ytest_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9943502824858756"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(v,ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=model1.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47396963123644253"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(v,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logistic': 38, 'svc': 90}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1={\"logistic\":38,\"svc\":90}\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict_values' object has no attribute 'sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16068\\2540639356.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict_values' object has no attribute 'sort'"
     ]
    }
   ],
   "source": [
    "list1.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ytest.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.RandomForestClassifier"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check1(model1):\n",
    "    model1.predict (xtest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "check1(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    parameter={'learning_rate':[1e-3,1e-2,1e-1,1,5],'max_depth':[1,3,5,10]}\n",
    "                model=GridSearchCV(XGBClassifier(random_state=42,max_iter=100),param_grid=parameter,cv=5)\n",
    "                model.fit(self.xtrain,self.ytrain_mapped)\n",
    "                best_estimator=model.best_params_\n",
    "                learning_rate=best_estimator['learning_rate']\n",
    "                max_depth=best_estimator['max_depth']\n",
    "                model1=XGBClassifier(random_state=42,max_iter=100,max_depth=max_depth,learning_rate=learning_rate)\n",
    "                model1.fit(self.xtrain,self.ytrain_mapped)\n",
    "                return model1\n",
    "            except Exception as e:\n",
    "                raise exception(e,sys) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rajes\\\\wafer_detection\\\\notebook'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\rajes\\\\wafer_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\"\n",
    "    Raw String: You can use a raw string by prefixing the string with r. This tells Python to interpret the string literally without treating escape characters:\n",
    "\n",
    "    \"\"\"\n",
    "path=r\"C:\\Users\\rajes\\wafer_detection\\Training_Batch_Files\\Wafer_15010_130532.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "er=pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "er['rajesh']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "      <th>rajesh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wafer-800</td>\n",
       "      <td>3002.22</td>\n",
       "      <td>2462.06</td>\n",
       "      <td>2202.1222</td>\n",
       "      <td>1833.3772</td>\n",
       "      <td>1.8005</td>\n",
       "      <td>100</td>\n",
       "      <td>95.8500</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.4182</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>33.7876</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wafer-500</td>\n",
       "      <td>3047.28</td>\n",
       "      <td>2186.06</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4619</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.6229</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>81.9472</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wafer-501</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>...</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wafer-502</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wafer-503</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wafer-595</td>\n",
       "      <td>2989.44</td>\n",
       "      <td>2487.66</td>\n",
       "      <td>2201.0667</td>\n",
       "      <td>880.2317</td>\n",
       "      <td>1.4148</td>\n",
       "      <td>100</td>\n",
       "      <td>106.5478</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>1.5301</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>2.5579</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>65.4831</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wafer-596</td>\n",
       "      <td>2996.89</td>\n",
       "      <td>2492.40</td>\n",
       "      <td>2217.8667</td>\n",
       "      <td>1275.0917</td>\n",
       "      <td>1.5487</td>\n",
       "      <td>100</td>\n",
       "      <td>105.2933</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.5455</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.4294</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>65.4831</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wafer-597</td>\n",
       "      <td>2990.85</td>\n",
       "      <td>2485.99</td>\n",
       "      <td>2167.9444</td>\n",
       "      <td>861.8041</td>\n",
       "      <td>1.4140</td>\n",
       "      <td>100</td>\n",
       "      <td>106.6033</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>1.4647</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5015</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>2.5884</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>65.4831</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wafer-598</td>\n",
       "      <td>3059.43</td>\n",
       "      <td>2473.55</td>\n",
       "      <td>2214.9333</td>\n",
       "      <td>1663.7024</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>100</td>\n",
       "      <td>100.4456</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4262</td>\n",
       "      <td>...</td>\n",
       "      <td>108.6076</td>\n",
       "      <td>0.4973</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1.4716</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>108.6076</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Wafer-599</td>\n",
       "      <td>3024.54</td>\n",
       "      <td>2420.25</td>\n",
       "      <td>2167.9444</td>\n",
       "      <td>861.8041</td>\n",
       "      <td>1.4140</td>\n",
       "      <td>100</td>\n",
       "      <td>106.6033</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>1.4849</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1.3667</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>108.6076</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows  592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  Sensor-1  Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  \\\n",
       "0    Wafer-800   3002.22   2462.06  2202.1222  1833.3772    1.8005       100   \n",
       "1    Wafer-500   3047.28   2186.06  2235.0556  1302.6607    1.6347       100   \n",
       "2    Wafer-501   3076.81   2158.75  2208.2334  1517.0152    1.0980       100   \n",
       "3    Wafer-502   2951.62   2511.92  2253.5111  1397.5060    0.9660       100   \n",
       "4    Wafer-503   2930.42   2505.17  2235.0556  1302.6607    1.6347       100   \n",
       "..         ...       ...       ...        ...        ...       ...       ...   \n",
       "96   Wafer-595   2989.44   2487.66  2201.0667   880.2317    1.4148       100   \n",
       "97   Wafer-596   2996.89   2492.40  2217.8667  1275.0917    1.5487       100   \n",
       "98   Wafer-597   2990.85   2485.99  2167.9444   861.8041    1.4140       100   \n",
       "99   Wafer-598   3059.43   2473.55  2214.9333  1663.7024    1.0203       100   \n",
       "100  Wafer-599   3024.54   2420.25  2167.9444   861.8041    1.4140       100   \n",
       "\n",
       "     Sensor-7  Sensor-8  Sensor-9  ...  Sensor-582  Sensor-583  Sensor-584  \\\n",
       "0     95.8500    0.1242    1.5173  ...         NaN      0.5021      0.0071   \n",
       "1    109.9856    0.1230    1.4619  ...         NaN      0.4998      0.0131   \n",
       "2    110.1900    0.1247    1.4357  ...     64.2405      0.5016      0.0152   \n",
       "3    109.7611    0.1210    1.5527  ...      0.0000      0.4953      0.0105   \n",
       "4    109.9856    0.1230    1.4588  ...         NaN      0.4958      0.0111   \n",
       "..        ...       ...       ...  ...         ...         ...         ...   \n",
       "96   106.5478    0.1211    1.5301  ...         NaN      0.4933      0.0126   \n",
       "97   105.2933    0.1230    1.5455  ...         NaN      0.5071      0.0123   \n",
       "98   106.6033    0.1243    1.4647  ...         NaN      0.5015      0.0130   \n",
       "99   100.4456    0.1247    1.4262  ...    108.6076      0.4973      0.0073   \n",
       "100  106.6033    0.1243    1.4849  ...         NaN      0.5006      0.0068   \n",
       "\n",
       "     Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  Sensor-590  \\\n",
       "0        0.0024      1.4182      0.0545      0.0184      0.0055     33.7876   \n",
       "1        0.0033      2.6229      0.0222      0.0182      0.0060     81.9472   \n",
       "2        0.0040      3.0319      0.0465      0.0299      0.0090     64.2405   \n",
       "3        0.0037      2.1266     -0.0012      0.0252      0.0081      0.0000   \n",
       "4        0.0033      2.2296     -0.0012      0.0252      0.0081      0.0000   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "96       0.0032      2.5579      0.0227      0.0149      0.0052     65.4831   \n",
       "97       0.0038      2.4294      0.0227      0.0149      0.0052     65.4831   \n",
       "98       0.0042      2.5884      0.0227      0.0149      0.0052     65.4831   \n",
       "99       0.0017      1.4716      0.0300      0.0326      0.0114    108.6076   \n",
       "100      0.0018      1.3667      0.0300      0.0326      0.0114    108.6076   \n",
       "\n",
       "     rajesh  \n",
       "0      None  \n",
       "1      None  \n",
       "2      None  \n",
       "3      None  \n",
       "4      None  \n",
       "..      ...  \n",
       "96     None  \n",
       "97     None  \n",
       "98     None  \n",
       "99     None  \n",
       "100    None  \n",
       "\n",
       "[101 rows x 592 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shape=er.shape\n",
    "for i in er:\n",
    "    if er[i].isna().sum()==shape[0]:\n",
    "        er.drop([i],axis=1,inplace=True)\n",
    "    else:\n",
    "        er[i].fillna('NULL',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 592)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "96     False\n",
       "97     False\n",
       "98     False\n",
       "99     False\n",
       "100    False\n",
       "Name: Sensor-582, Length: 101, dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er['Sensor-582'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wafer-800</td>\n",
       "      <td>3002.22</td>\n",
       "      <td>2462.06</td>\n",
       "      <td>2202.1222</td>\n",
       "      <td>1833.3772</td>\n",
       "      <td>1.8005</td>\n",
       "      <td>100</td>\n",
       "      <td>95.8500</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0.5021</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.4182</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>33.7876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wafer-500</td>\n",
       "      <td>3047.28</td>\n",
       "      <td>2186.06</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4619</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.6229</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>81.9472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wafer-501</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wafer-502</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wafer-503</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wafer-595</td>\n",
       "      <td>2989.44</td>\n",
       "      <td>2487.66</td>\n",
       "      <td>2201.0667</td>\n",
       "      <td>880.2317</td>\n",
       "      <td>1.4148</td>\n",
       "      <td>100</td>\n",
       "      <td>106.5478</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>1.5301</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>2.5579</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>65.4831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wafer-596</td>\n",
       "      <td>2996.89</td>\n",
       "      <td>2492.4</td>\n",
       "      <td>2217.8667</td>\n",
       "      <td>1275.0917</td>\n",
       "      <td>1.5487</td>\n",
       "      <td>100</td>\n",
       "      <td>105.2933</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.5455</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0.5071</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.4294</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>65.4831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Wafer-597</td>\n",
       "      <td>2990.85</td>\n",
       "      <td>2485.99</td>\n",
       "      <td>2167.9444</td>\n",
       "      <td>861.8041</td>\n",
       "      <td>1.4140</td>\n",
       "      <td>100</td>\n",
       "      <td>106.6033</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>1.4647</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0.5015</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>2.5884</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>65.4831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Wafer-598</td>\n",
       "      <td>3059.43</td>\n",
       "      <td>2473.55</td>\n",
       "      <td>2214.9333</td>\n",
       "      <td>1663.7024</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>100</td>\n",
       "      <td>100.4456</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>108.608</td>\n",
       "      <td>0.4973</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>1.4716</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>108.6076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Wafer-599</td>\n",
       "      <td>3024.54</td>\n",
       "      <td>2420.25</td>\n",
       "      <td>2167.9444</td>\n",
       "      <td>861.8041</td>\n",
       "      <td>1.4140</td>\n",
       "      <td>100</td>\n",
       "      <td>106.6033</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>1.4849</td>\n",
       "      <td>...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>0.5006</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>1.3667</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>108.6076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows  575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 Sensor-1 Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  \\\n",
       "0    Wafer-800  3002.22  2462.06  2202.1222  1833.3772    1.8005       100   \n",
       "1    Wafer-500  3047.28  2186.06  2235.0556  1302.6607    1.6347       100   \n",
       "2    Wafer-501  3076.81  2158.75  2208.2334  1517.0152    1.0980       100   \n",
       "3    Wafer-502  2951.62  2511.92  2253.5111  1397.5060    0.9660       100   \n",
       "4    Wafer-503  2930.42  2505.17  2235.0556  1302.6607    1.6347       100   \n",
       "..         ...      ...      ...        ...        ...       ...       ...   \n",
       "96   Wafer-595  2989.44  2487.66  2201.0667   880.2317    1.4148       100   \n",
       "97   Wafer-596  2996.89   2492.4  2217.8667  1275.0917    1.5487       100   \n",
       "98   Wafer-597  2990.85  2485.99  2167.9444   861.8041    1.4140       100   \n",
       "99   Wafer-598  3059.43  2473.55  2214.9333  1663.7024    1.0203       100   \n",
       "100  Wafer-599  3024.54  2420.25  2167.9444   861.8041    1.4140       100   \n",
       "\n",
       "     Sensor-7  Sensor-8  Sensor-9  ...  Sensor-581  Sensor-582  Sensor-583  \\\n",
       "0     95.8500    0.1242    1.5173  ...        NULL        NULL      0.5021   \n",
       "1    109.9856    0.1230    1.4619  ...        NULL        NULL      0.4998   \n",
       "2    110.1900    0.1247    1.4357  ...       0.009     64.2405      0.5016   \n",
       "3    109.7611    0.1210    1.5527  ...      0.0081           0      0.4953   \n",
       "4    109.9856    0.1230    1.4588  ...        NULL        NULL      0.4958   \n",
       "..        ...       ...       ...  ...         ...         ...         ...   \n",
       "96   106.5478    0.1211    1.5301  ...        NULL        NULL      0.4933   \n",
       "97   105.2933    0.1230    1.5455  ...        NULL        NULL      0.5071   \n",
       "98   106.6033    0.1243    1.4647  ...        NULL        NULL      0.5015   \n",
       "99   100.4456    0.1247    1.4262  ...      0.0114     108.608      0.4973   \n",
       "100  106.6033    0.1243    1.4849  ...        NULL        NULL      0.5006   \n",
       "\n",
       "     Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n",
       "0        0.0071      0.0024      1.4182      0.0545      0.0184      0.0055   \n",
       "1        0.0131      0.0033      2.6229      0.0222      0.0182      0.0060   \n",
       "2        0.0152      0.0040      3.0319      0.0465      0.0299      0.0090   \n",
       "3        0.0105      0.0037      2.1266     -0.0012      0.0252      0.0081   \n",
       "4        0.0111      0.0033      2.2296     -0.0012      0.0252      0.0081   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "96       0.0126      0.0032      2.5579      0.0227      0.0149      0.0052   \n",
       "97       0.0123      0.0038      2.4294      0.0227      0.0149      0.0052   \n",
       "98       0.0130      0.0042      2.5884      0.0227      0.0149      0.0052   \n",
       "99       0.0073      0.0017      1.4716      0.0300      0.0326      0.0114   \n",
       "100      0.0068      0.0018      1.3667      0.0300      0.0326      0.0114   \n",
       "\n",
       "     Sensor-590  \n",
       "0       33.7876  \n",
       "1       81.9472  \n",
       "2       64.2405  \n",
       "3        0.0000  \n",
       "4        0.0000  \n",
       "..          ...  \n",
       "96      65.4831  \n",
       "97      65.4831  \n",
       "98      65.4831  \n",
       "99     108.6076  \n",
       "100    108.6076  \n",
       "\n",
       "[101 rows x 575 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path=r\"C:\\Users\\rajes\\wafer_detection\\Prediction_Batch_files\"\n",
    "import  os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "list4=[]\n",
    "files=[file_name for file_name in os.listdir(data_file_path)]\n",
    "list1=[]\n",
    "for file_name in files:\n",
    "    file_name=file_name.split('.csv')[0]\n",
    "    file_name=file_name.split('_')\n",
    "    list1.append(file_name)\n",
    "    for i in range(len(list1)):\n",
    "        if len(list1[i])!=3:\n",
    "            continue\n",
    "        \n",
    "        test1=re.fullmatch('wafer',list1[i][0]) \n",
    "        test2=re.fullmatch(r'\\d+',list1[i][1])\n",
    "        test3=re.fullmatch(r'\\d+',list1[i][2])\n",
    "        count=0\n",
    "        if test1:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        if test2:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        if test3:\n",
    "            pass\n",
    "        else:\n",
    "            continue\n",
    "        list4.append(file_name)\n",
    "list2=[]\n",
    "list3=[]\n",
    "for i in range(len(list4)):\n",
    "    if len(list4[i][1])==8 and len(list4[i][2])==6:\n",
    "        list3.append(list4[i])     \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wafer', '07012020', '041011'],\n",
       " ['wafer', '13012020', '090817'],\n",
       " ['wafer', '13012020', '090817'],\n",
       " ['Wafer', '13012020', '141000'],\n",
       " ['Wafer', '13012020', '141000'],\n",
       " ['Wafer', '14012020', '113045'],\n",
       " ['Wafer', '14012020', '113045'],\n",
       " ['Wafer', '15010', '130532'],\n",
       " ['Wafer', '15010', '130532'],\n",
       " ['wafer', '16012020', '051629'],\n",
       " ['wafer', '16012020', '051629'],\n",
       " ['wafer', '16012020', '051629'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811']]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16088\\2200557889.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlist3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mlist2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "    list2=[]\n",
    "    list3=[]\n",
    "    for file_name in list4:\n",
    "            file_name=file_name.split('.csv')[0]\n",
    "            file_name=file_name.split('_')\n",
    "            list2.append(file_name)\n",
    "    for i in range(len(list2)):\n",
    "        if len(list2[i][1])==self.LengthOfDateStampInFile and len(list2[i][2])==self.LengthOfTimeStampInFile:\n",
    "           list3[list2[i]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wafer', '07012020', '041011']\n",
      "['wafer', '13012020', '090817']\n",
      "['wafer', '13012020', '090817']\n",
      "['Wafer', '13012020', '141000']\n",
      "['Wafer', '13012020', '141000']\n",
      "['Wafer', '14012020', '113045']\n",
      "['Wafer', '14012020', '113045']\n",
      "['Wafer', '15010', '130532']\n",
      "['Wafer', '15010', '130532']\n",
      "['wafer', '16012020', '051629']\n",
      "['wafer', '16012020', '051629']\n",
      "['wafer', '16012020', '051629']\n",
      "['wafer', '20012020', '090819']\n",
      "['wafer', '20012020', '090819']\n",
      "['wafer', '20012020', '090819']\n",
      "['wafer', '20012020', '090819']\n",
      "['wafer', '20022020', '090716']\n",
      "['wafer', '20022020', '090716']\n",
      "['wafer', '20022020', '090716']\n",
      "['wafer', '20022020', '090716']\n",
      "['wafer', '20022020', '090716']\n",
      "['wafer', '21012020', '080913']\n",
      "['wafer', '21012020', '080913']\n",
      "['wafer', '21012020', '080913']\n",
      "['wafer', '21012020', '080913']\n",
      "['wafer', '21012020', '080913']\n",
      "['wafer', '21012020', '080913']\n",
      "['wafer', '22022020', '041119']\n",
      "['wafer', '22022020', '041119']\n",
      "['wafer', '22022020', '041119']\n",
      "['wafer', '22022020', '041119']\n",
      "['wafer', '22022020', '041119']\n",
      "['wafer', '22022020', '041119']\n",
      "['wafer', '22022020', '041119']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '011008']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '23012020', '041211']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '27012020', '080911']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '051011']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28012020', '090817']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '28042020', '031911']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '050617']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '29012020', '060756']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n",
      "['wafer', '31012020', '090811']\n"
     ]
    }
   ],
   "source": [
    "for i in list4:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wafer', '07012020', '041011'],\n",
       " ['wafer', '13012020', '090817'],\n",
       " ['wafer', '13012020', '090817'],\n",
       " ['Wafer', '13012020', '141000'],\n",
       " ['Wafer', '13012020', '141000'],\n",
       " ['Wafer', '14012020', '113045'],\n",
       " ['Wafer', '14012020', '113045'],\n",
       " ['wafer', '16012020', '051629'],\n",
       " ['wafer', '16012020', '051629'],\n",
       " ['wafer', '16012020', '051629'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20012020', '090819'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '20022020', '090716'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '21012020', '080913'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '22022020', '041119'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '011008'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '23012020', '041211'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '27012020', '080911'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '051011'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28012020', '090817'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '28042020', '031911'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '050617'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '29012020', '060756'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811'],\n",
       " ['wafer', '31012020', '090811']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[file_name for file_name in os.listdir(data_file_path)]\n",
    "list1=[]\n",
    "for file_name in files:\n",
    "    file_name=file_name.split('.csv')[0]\n",
    "    file_name=file_name.split('_')\n",
    "    list1.append(file_name)\n",
    "for i in range(len(list1)):\n",
    "    if len(list1[i])!=3:\n",
    "        shutil.copy(data_file_path+'/'+files[i],bad_file_path+'/'+files[i])\n",
    "        continue\n",
    "        \n",
    "    test1=re.fullmatch('wafer',list1[i][0]) \n",
    "    test2=re.fullmatch(r'\\d+',list1[i][1])\n",
    "    test3=re.fullmatch(r'\\d+',list1[i][2])\n",
    "    \n",
    "    if test1:\n",
    "        pass\n",
    "    else:\n",
    "        shutil.copy(data_file_path+'/'+files[i],bad_file_path+'/'+files[i])\n",
    "        continue\n",
    "    if test2:\n",
    "        pass\n",
    "    else:\n",
    "        shutil.copy(data_file_path+'/'+files[i],bad_file_path+'/'+files[i])\n",
    "        continue \n",
    "    if test3:\n",
    "        pass\n",
    "    else:\n",
    "        shutil.copy(data_file_path+'/'+files[i],bad_file_path+'/'+files[i])\n",
    "        continue\n",
    "    file_path1=os.path.join(good_file_path,files[i])\n",
    "    file_path2=os.path.join(data_file_path,files[i])\n",
    "    shutil.copy(file_path2,file_path1)\n",
    "files1=[file_name for file_name in os.listdir(good_file_path) ]\n",
    "list2=[]\n",
    "for file_name in files1:\n",
    "        file_name=file_name.split('.csv')[0]\n",
    "        file_name=file_name.split('_')\n",
    "        list2.append(file_name)\n",
    "for i in range(len(list2)):\n",
    "    if len(list2[i][1])==8 and len(list2[i][2])==6:\n",
    "        pass\n",
    "    else:\n",
    "        shutil.move(good_file_path+'/'+files1[i],bad_file_path+'/'+files1[i])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_file_path=os.path.join(root_dir,'predict_goodfiles')\n",
    "bad_file_path=os.path.join(root_dir+'predict_badfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('c:\\\\Users\\\\rajes\\\\wafer_detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path=r\"C:\\Users\\rajes\\wafer_detection\\Prediction_Batch_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (3147840388.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\rajes\\AppData\\Local\\Temp\\ipykernel_16088\\3147840388.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    C:\\Users\\rajes\\wafer_detection\\Prediction_Batch_files\\wafer_07012020_041011.csv\u001b[0m\n\u001b[1;37m                                                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "C:\\Users\\rajes\\wafer_detection\\Prediction_Batch_files\\wafer_07012020_041011.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(r'C:\\Users\\rajes\\wafer_detection\\Prediction_Batch_files\\wafer_07012020_041011.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(good_file_path,exist_ok=True)\n",
    "os.makedirs(bad_file_path,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Unnamed: 0\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Unnamed: 0.1\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3074, 591), indices imply (591, 591)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1674\u001b[1;33m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1675\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (3074, 591), indices imply (591, 591)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16088\\4064093364.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnd_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpkl_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnd_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[1;34m(blocks, axes)\u001b[0m\n\u001b[0;32m   1679\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"values\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1680\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1681\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (3074, 591), indices imply (591, 591)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "file2=root_dir+'/data_preprocessing/imputer.pkl'\n",
    "pkl_model=pickle.load(open(file2,'rb'))\n",
    "nd_array=pkl_model.transform(df1)\n",
    "columns=df1.columns\n",
    "df2=pd.DataFrame(nd_array,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\rajes\\\\wafer_detection'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir=os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Wafer</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-501</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wafer-502</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Wafer-503</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wafer-504</td>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>1236.5212</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Wafer-505</td>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3069</td>\n",
       "      <td>Wafer-396</td>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1425.1041</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>3070</td>\n",
       "      <td>Wafer-397</td>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1202.4520</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3071</td>\n",
       "      <td>Wafer-398</td>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1657.3518</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.0147</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3072</td>\n",
       "      <td>Wafer-399</td>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1351.9648</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3073</td>\n",
       "      <td>Wafer-400</td>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1448.8499</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      Wafer  Sensor-1  Sensor-2   Sensor-3   Sensor-4  \\\n",
       "0              0  Wafer-501   3076.81   2158.75  2208.2334  1517.0152   \n",
       "1              1  Wafer-502   2951.62   2511.92  2253.5111  1397.5060   \n",
       "2              2  Wafer-503   2930.42   2505.17  2235.0556  1302.6607   \n",
       "3              3  Wafer-504   2997.28   2357.99  2141.0667  1236.5212   \n",
       "4              4  Wafer-505   3025.10   2475.18  2235.0556  1302.6607   \n",
       "...          ...        ...       ...       ...        ...        ...   \n",
       "3069        3069  Wafer-396   3079.17   2405.56  2217.3777  1425.1041   \n",
       "3070        3070  Wafer-397   2911.37   2541.21  2207.8111  1202.4520   \n",
       "3071        3071  Wafer-398   3085.57   2364.78  2178.6889  1657.3518   \n",
       "3072        3072  Wafer-399   3053.49   2457.08  2172.5333  1351.9648   \n",
       "3073        3073  Wafer-400   3120.68   2396.40  2177.0222  1448.8499   \n",
       "\n",
       "      Sensor-5  Sensor-6  Sensor-7  Sensor-8  ...  Sensor-581  Sensor-582  \\\n",
       "0       1.0980     100.0  110.1900    0.1247  ...      0.0090     64.2405   \n",
       "1       0.9660     100.0  109.7611    0.1210  ...      0.0081      0.0000   \n",
       "2       1.6347     100.0  109.9856    0.1230  ...         NaN         NaN   \n",
       "3       0.9698     100.0   98.3344    0.1238  ...         NaN         NaN   \n",
       "4       1.6347     100.0  109.9856    0.1230  ...         NaN         NaN   \n",
       "...        ...       ...       ...       ...  ...         ...         ...   \n",
       "3069    1.7585     100.0  106.2556    0.1200  ...      0.0024     31.3771   \n",
       "3070    1.6219     100.0  108.7689    0.1212  ...         NaN         NaN   \n",
       "3071    1.6603     100.0  100.8022    0.1229  ...      0.0044    109.5996   \n",
       "3072    1.6377     100.0  103.8800    0.1243  ...         NaN         NaN   \n",
       "3073    1.5565     100.0  103.2567    0.1232  ...         NaN         NaN   \n",
       "\n",
       "      Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  \\\n",
       "0         0.5016      0.0152      0.0040      3.0319      0.0465      0.0299   \n",
       "1         0.4953      0.0105      0.0037      2.1266     -0.0012      0.0252   \n",
       "2         0.4958      0.0111      0.0033      2.2296     -0.0012      0.0252   \n",
       "3         0.4962      0.0086      0.0024      1.7297     -0.0012      0.0252   \n",
       "4         0.4983      0.0159      0.0041      3.1927     -0.0012      0.0252   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069      0.5080      0.0139      0.0039      2.7328      0.0234      0.0073   \n",
       "3070         NaN         NaN         NaN         NaN      0.0234      0.0073   \n",
       "3071      0.4986      0.0147      0.0038      2.9493      0.0142      0.0156   \n",
       "3072      0.4981      0.0132      0.0035      2.6491      0.0142      0.0156   \n",
       "3073      0.4975      0.0140      0.0036      2.8098      0.0142      0.0156   \n",
       "\n",
       "      Sensor-589  Sensor-590  \n",
       "0         0.0090     64.2405  \n",
       "1         0.0081      0.0000  \n",
       "2         0.0081      0.0000  \n",
       "3         0.0081      0.0000  \n",
       "4         0.0081      0.0000  \n",
       "...          ...         ...  \n",
       "3069      0.0024     31.3771  \n",
       "3070      0.0024     31.3771  \n",
       "3071      0.0044    109.5996  \n",
       "3072      0.0044    109.5996  \n",
       "3073      0.0044    109.5996  \n",
       "\n",
       "[3074 rows x 592 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "file1=root_dir+'/predict_data_ingestion/input.csv'\n",
    "df1=pd.read_csv(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "wafer=df1['Wafer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Sensor-501'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    False\n",
       "Sensor-1      False\n",
       "Sensor-2      False\n",
       "Sensor-3      False\n",
       "Sensor-4      False\n",
       "              ...  \n",
       "Sensor-586    False\n",
       "Sensor-587    False\n",
       "Sensor-588    False\n",
       "Sensor-589    False\n",
       "Sensor-590    False\n",
       "Length: 591, dtype: bool"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dtypes=='object'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['Wafer'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3074, 591)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3074, 591)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(nd_array,columns=df1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2=r\"C:\\Users\\rajes\\wafer_detection\\data_preprocessing\\cluster.pkl\"\n",
    "cluster_model=pickle.load(open(path2,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop([\"Unnamed: 0\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>64.240500</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>81.250167</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>1236.5212</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>44.249467</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>84.270400</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1425.1041</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>31.377100</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1202.4520</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>81.147333</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>2.3590</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1657.3518</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>109.599600</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1351.9648</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>106.370067</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1448.8499</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>69.267033</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3   Sensor-4  Sensor-5  Sensor-6  Sensor-7  \\\n",
       "0      3076.81   2158.75  2208.2334  1517.0152    1.0980     100.0  110.1900   \n",
       "1      2951.62   2511.92  2253.5111  1397.5060    0.9660     100.0  109.7611   \n",
       "2      2930.42   2505.17  2235.0556  1302.6607    1.6347     100.0  109.9856   \n",
       "3      2997.28   2357.99  2141.0667  1236.5212    0.9698     100.0   98.3344   \n",
       "4      3025.10   2475.18  2235.0556  1302.6607    1.6347     100.0  109.9856   \n",
       "...        ...       ...        ...        ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777  1425.1041    1.7585     100.0  106.2556   \n",
       "3070   2911.37   2541.21  2207.8111  1202.4520    1.6219     100.0  108.7689   \n",
       "3071   3085.57   2364.78  2178.6889  1657.3518    1.6603     100.0  100.8022   \n",
       "3072   3053.49   2457.08  2172.5333  1351.9648    1.6377     100.0  103.8800   \n",
       "3073   3120.68   2396.40  2177.0222  1448.8499    1.5565     100.0  103.2567   \n",
       "\n",
       "      Sensor-8  Sensor-9  Sensor-10  ...  Sensor-581  Sensor-582  Sensor-583  \\\n",
       "0       0.1247    1.4357     0.0089  ...    0.009000   64.240500      0.5016   \n",
       "1       0.1210    1.5527     0.0119  ...    0.008100    0.000000      0.4953   \n",
       "2       0.1230    1.4588    -0.0143  ...    0.007333   81.250167      0.4958   \n",
       "3       0.1238    1.5973    -0.0534  ...    0.004733   44.249467      0.4962   \n",
       "4       0.1230    1.5525    -0.0078  ...    0.005867   84.270400      0.4983   \n",
       "...        ...       ...        ...  ...         ...         ...         ...   \n",
       "3069    0.1200    1.4794    -0.0198  ...    0.002400   31.377100      0.5080   \n",
       "3070    0.1212    1.5322     0.0205  ...    0.005200   81.147333      0.5026   \n",
       "3071    0.1229    1.4945     0.0247  ...    0.004400  109.599600      0.4986   \n",
       "3072    0.1243    1.5680     0.0009  ...    0.006233  106.370067      0.4981   \n",
       "3073    0.1232    1.4920    -0.0095  ...    0.005333   69.267033      0.4975   \n",
       "\n",
       "      Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n",
       "0       0.015200    0.004000      3.0319      0.0465      0.0299      0.0090   \n",
       "1       0.010500    0.003700      2.1266     -0.0012      0.0252      0.0081   \n",
       "2       0.011100    0.003300      2.2296     -0.0012      0.0252      0.0081   \n",
       "3       0.008600    0.002400      1.7297     -0.0012      0.0252      0.0081   \n",
       "4       0.015900    0.004100      3.1927     -0.0012      0.0252      0.0081   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069    0.013900    0.003900      2.7328      0.0234      0.0073      0.0024   \n",
       "3070    0.011867    0.003133      2.3590      0.0234      0.0073      0.0024   \n",
       "3071    0.014700    0.003800      2.9493      0.0142      0.0156      0.0044   \n",
       "3072    0.013200    0.003500      2.6491      0.0142      0.0156      0.0044   \n",
       "3073    0.014000    0.003600      2.8098      0.0142      0.0156      0.0044   \n",
       "\n",
       "      Sensor-590  \n",
       "0        64.2405  \n",
       "1         0.0000  \n",
       "2         0.0000  \n",
       "3         0.0000  \n",
       "4         0.0000  \n",
       "...          ...  \n",
       "3069     31.3771  \n",
       "3070     31.3771  \n",
       "3071    109.5996  \n",
       "3072    109.5996  \n",
       "3073    109.5996  \n",
       "\n",
       "[3074 rows x 590 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- Sensor-113\n",
      "- Sensor-115\n",
      "- Sensor-129\n",
      "- Sensor-14\n",
      "- Sensor-140\n",
      "- ...\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 590 features, but KMeans is expecting 403 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16088\\3787747558.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcluster_numbers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcluster_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m             \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m         )\n\u001b[0;32m   1015\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m             raise ValueError(\n\u001b[1;32m--> 401\u001b[1;33m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 590 features, but KMeans is expecting 403 features as input."
     ]
    }
   ],
   "source": [
    "cluster_numbers=cluster_model.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "exception",
     "evalue": "\n        Error occured in script: \n        [ c:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py ] at \n        try block line number: [173] and exception block line number: [212] \n        error message: [\n        Error occured in script: \n        [ c:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py ] at \n        try block line number: [34] and exception block line number: [37] \n        error message: [\"['Wafer'] not found in axis\"]\n        ]\n        ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py\u001b[0m in \u001b[0;36mdeletion_of_a_columns\u001b[1;34m(self, columns, dataframe)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4174\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4175\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3888\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3889\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3922\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3923\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5286\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5287\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Wafer'] not found in axis\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mexception\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[1;31m#self.Modified_dataframe=self. deletion_of_a_columns(['Wafer','Unnamed: 0'],self.data_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py\u001b[0m in \u001b[0;36mdeletion_of_a_columns\u001b[1;34m(self, columns, dataframe)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mexception\u001b[0m: \n        Error occured in script: \n        [ c:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py ] at \n        try block line number: [34] and exception block line number: [37] \n        error message: [\"['Wafer'] not found in axis\"]\n        ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mexception\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16088\\1494338012.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mobj1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns_with_zero_deviation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mexception\u001b[0m: \n        Error occured in script: \n        [ c:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py ] at \n        try block line number: [173] and exception block line number: [212] \n        error message: [\n        Error occured in script: \n        [ c:\\Users\\rajes\\wafer_detection\\data_preprocessing\\__init__.py ] at \n        try block line number: [34] and exception block line number: [37] \n        error message: [\"['Wafer'] not found in axis\"]\n        ]\n        "
     ]
    }
   ],
   "source": [
    "from data_preprocessing import preprocessing\n",
    "obj1=preprocessing()\n",
    "columns=obj1.columns_with_zero_deviation(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>64.240500</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>81.250167</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>1236.5212</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>44.249467</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>84.270400</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3069.0</td>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1425.1041</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>31.377100</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>3070.0</td>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1202.4520</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>81.147333</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>2.3590</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3071.0</td>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1657.3518</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>109.599600</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3072.0</td>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1351.9648</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>106.370067</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3073.0</td>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1448.8499</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>69.267033</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Sensor-1  Sensor-2   Sensor-3   Sensor-4  Sensor-5  \\\n",
       "0            0.0   3076.81   2158.75  2208.2334  1517.0152    1.0980   \n",
       "1            1.0   2951.62   2511.92  2253.5111  1397.5060    0.9660   \n",
       "2            2.0   2930.42   2505.17  2235.0556  1302.6607    1.6347   \n",
       "3            3.0   2997.28   2357.99  2141.0667  1236.5212    0.9698   \n",
       "4            4.0   3025.10   2475.18  2235.0556  1302.6607    1.6347   \n",
       "...          ...       ...       ...        ...        ...       ...   \n",
       "3069      3069.0   3079.17   2405.56  2217.3777  1425.1041    1.7585   \n",
       "3070      3070.0   2911.37   2541.21  2207.8111  1202.4520    1.6219   \n",
       "3071      3071.0   3085.57   2364.78  2178.6889  1657.3518    1.6603   \n",
       "3072      3072.0   3053.49   2457.08  2172.5333  1351.9648    1.6377   \n",
       "3073      3073.0   3120.68   2396.40  2177.0222  1448.8499    1.5565   \n",
       "\n",
       "      Sensor-6  Sensor-7  Sensor-8  Sensor-9  ...  Sensor-581  Sensor-582  \\\n",
       "0        100.0  110.1900    0.1247    1.4357  ...    0.009000   64.240500   \n",
       "1        100.0  109.7611    0.1210    1.5527  ...    0.008100    0.000000   \n",
       "2        100.0  109.9856    0.1230    1.4588  ...    0.007333   81.250167   \n",
       "3        100.0   98.3344    0.1238    1.5973  ...    0.004733   44.249467   \n",
       "4        100.0  109.9856    0.1230    1.5525  ...    0.005867   84.270400   \n",
       "...        ...       ...       ...       ...  ...         ...         ...   \n",
       "3069     100.0  106.2556    0.1200    1.4794  ...    0.002400   31.377100   \n",
       "3070     100.0  108.7689    0.1212    1.5322  ...    0.005200   81.147333   \n",
       "3071     100.0  100.8022    0.1229    1.4945  ...    0.004400  109.599600   \n",
       "3072     100.0  103.8800    0.1243    1.5680  ...    0.006233  106.370067   \n",
       "3073     100.0  103.2567    0.1232    1.4920  ...    0.005333   69.267033   \n",
       "\n",
       "      Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  \\\n",
       "0         0.5016    0.015200    0.004000      3.0319      0.0465      0.0299   \n",
       "1         0.4953    0.010500    0.003700      2.1266     -0.0012      0.0252   \n",
       "2         0.4958    0.011100    0.003300      2.2296     -0.0012      0.0252   \n",
       "3         0.4962    0.008600    0.002400      1.7297     -0.0012      0.0252   \n",
       "4         0.4983    0.015900    0.004100      3.1927     -0.0012      0.0252   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069      0.5080    0.013900    0.003900      2.7328      0.0234      0.0073   \n",
       "3070      0.5026    0.011867    0.003133      2.3590      0.0234      0.0073   \n",
       "3071      0.4986    0.014700    0.003800      2.9493      0.0142      0.0156   \n",
       "3072      0.4981    0.013200    0.003500      2.6491      0.0142      0.0156   \n",
       "3073      0.4975    0.014000    0.003600      2.8098      0.0142      0.0156   \n",
       "\n",
       "      Sensor-589  Sensor-590  \n",
       "0         0.0090     64.2405  \n",
       "1         0.0081      0.0000  \n",
       "2         0.0081      0.0000  \n",
       "3         0.0081      0.0000  \n",
       "4         0.0081      0.0000  \n",
       "...          ...         ...  \n",
       "3069      0.0024     31.3771  \n",
       "3070      0.0024     31.3771  \n",
       "3071      0.0044    109.5996  \n",
       "3072      0.0044    109.5996  \n",
       "3073      0.0044    109.5996  \n",
       "\n",
       "[3074 rows x 591 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_with_zero_std_deviation(dataframe)->list:\n",
    "        \"\"\"\n",
    "        Description:Checking if any column in the dataframe have zero standard deviation and returning column names in the form of list\n",
    "        output:list\n",
    "        failure:Raise exception\n",
    "        \"\"\"\n",
    "        try:\n",
    "            list1=[]\n",
    "            std_values=dataframe.describe().iloc[3,:]\n",
    "            std_values=dict(std_values)\n",
    "            for i in std_values:\n",
    "                if std_values[i]==0.0:\n",
    "                    list1.append(i)\n",
    "            return list1\n",
    "        except Exception as e:\n",
    "            raise exception(e,sys) from e\n",
    "            logging.info(exception(e,sys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=columns_with_zero_std_deviation(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Sensor-4',\n",
       " 'Sensor-8',\n",
       " 'Sensor-14',\n",
       " 'Sensor-23',\n",
       " 'Sensor-26',\n",
       " 'Sensor-27',\n",
       " 'Sensor-28',\n",
       " 'Sensor-53',\n",
       " 'Sensor-75',\n",
       " 'Sensor-98',\n",
       " 'Sensor-113',\n",
       " 'Sensor-115',\n",
       " 'Sensor-129',\n",
       " 'Sensor-140',\n",
       " 'Sensor-142',\n",
       " 'Sensor-144',\n",
       " 'Sensor-150',\n",
       " 'Sensor-160',\n",
       " 'Sensor-161',\n",
       " 'Sensor-162',\n",
       " 'Sensor-163',\n",
       " 'Sensor-164',\n",
       " 'Sensor-165',\n",
       " 'Sensor-166',\n",
       " 'Sensor-179',\n",
       " 'Sensor-180',\n",
       " 'Sensor-187',\n",
       " 'Sensor-190',\n",
       " 'Sensor-191',\n",
       " 'Sensor-192',\n",
       " 'Sensor-193',\n",
       " 'Sensor-194',\n",
       " 'Sensor-195',\n",
       " 'Sensor-202',\n",
       " 'Sensor-203',\n",
       " 'Sensor-207',\n",
       " 'Sensor-210',\n",
       " 'Sensor-227',\n",
       " 'Sensor-230',\n",
       " 'Sensor-231',\n",
       " 'Sensor-232',\n",
       " 'Sensor-233',\n",
       " 'Sensor-234',\n",
       " 'Sensor-235',\n",
       " 'Sensor-236',\n",
       " 'Sensor-237',\n",
       " 'Sensor-238',\n",
       " 'Sensor-241',\n",
       " 'Sensor-242',\n",
       " 'Sensor-243',\n",
       " 'Sensor-244',\n",
       " 'Sensor-248',\n",
       " 'Sensor-250',\n",
       " 'Sensor-257',\n",
       " 'Sensor-258',\n",
       " 'Sensor-259',\n",
       " 'Sensor-260',\n",
       " 'Sensor-261',\n",
       " 'Sensor-262',\n",
       " 'Sensor-263',\n",
       " 'Sensor-264',\n",
       " 'Sensor-265',\n",
       " 'Sensor-266',\n",
       " 'Sensor-267',\n",
       " 'Sensor-275',\n",
       " 'Sensor-277',\n",
       " 'Sensor-279',\n",
       " 'Sensor-285',\n",
       " 'Sensor-295',\n",
       " 'Sensor-296',\n",
       " 'Sensor-297',\n",
       " 'Sensor-298',\n",
       " 'Sensor-299',\n",
       " 'Sensor-300',\n",
       " 'Sensor-301',\n",
       " 'Sensor-314',\n",
       " 'Sensor-315',\n",
       " 'Sensor-316',\n",
       " 'Sensor-323',\n",
       " 'Sensor-326',\n",
       " 'Sensor-327',\n",
       " 'Sensor-328',\n",
       " 'Sensor-329',\n",
       " 'Sensor-330',\n",
       " 'Sensor-331',\n",
       " 'Sensor-338',\n",
       " 'Sensor-339',\n",
       " 'Sensor-343',\n",
       " 'Sensor-348',\n",
       " 'Sensor-365',\n",
       " 'Sensor-368',\n",
       " 'Sensor-369',\n",
       " 'Sensor-370',\n",
       " 'Sensor-371',\n",
       " 'Sensor-372',\n",
       " 'Sensor-373',\n",
       " 'Sensor-374',\n",
       " 'Sensor-375',\n",
       " 'Sensor-376',\n",
       " 'Sensor-379',\n",
       " 'Sensor-380',\n",
       " 'Sensor-381',\n",
       " 'Sensor-382',\n",
       " 'Sensor-386',\n",
       " 'Sensor-388',\n",
       " 'Sensor-395',\n",
       " 'Sensor-396',\n",
       " 'Sensor-397',\n",
       " 'Sensor-398',\n",
       " 'Sensor-399',\n",
       " 'Sensor-400',\n",
       " 'Sensor-401',\n",
       " 'Sensor-402',\n",
       " 'Sensor-403',\n",
       " 'Sensor-404',\n",
       " 'Sensor-405',\n",
       " 'Sensor-413',\n",
       " 'Sensor-415',\n",
       " 'Sensor-417',\n",
       " 'Sensor-419',\n",
       " 'Sensor-420',\n",
       " 'Sensor-423',\n",
       " 'Sensor-431',\n",
       " 'Sensor-432',\n",
       " 'Sensor-433',\n",
       " 'Sensor-434',\n",
       " 'Sensor-435',\n",
       " 'Sensor-436',\n",
       " 'Sensor-437',\n",
       " 'Sensor-439',\n",
       " 'Sensor-450',\n",
       " 'Sensor-451',\n",
       " 'Sensor-452',\n",
       " 'Sensor-459',\n",
       " 'Sensor-462',\n",
       " 'Sensor-463',\n",
       " 'Sensor-464',\n",
       " 'Sensor-465',\n",
       " 'Sensor-466',\n",
       " 'Sensor-467',\n",
       " 'Sensor-469',\n",
       " 'Sensor-474',\n",
       " 'Sensor-475',\n",
       " 'Sensor-477',\n",
       " 'Sensor-479',\n",
       " 'Sensor-482',\n",
       " 'Sensor-483',\n",
       " 'Sensor-484',\n",
       " 'Sensor-485',\n",
       " 'Sensor-486',\n",
       " 'Sensor-487',\n",
       " 'Sensor-488',\n",
       " 'Sensor-489',\n",
       " 'Sensor-490',\n",
       " 'Sensor-499',\n",
       " 'Sensor-500',\n",
       " 'Sensor-501',\n",
       " 'Sensor-502',\n",
       " 'Sensor-503',\n",
       " 'Sensor-504',\n",
       " 'Sensor-505',\n",
       " 'Sensor-506',\n",
       " 'Sensor-507',\n",
       " 'Sensor-508',\n",
       " 'Sensor-509',\n",
       " 'Sensor-510',\n",
       " 'Sensor-511',\n",
       " 'Sensor-512',\n",
       " 'Sensor-513',\n",
       " 'Sensor-514',\n",
       " 'Sensor-515',\n",
       " 'Sensor-516',\n",
       " 'Sensor-520',\n",
       " 'Sensor-522',\n",
       " 'Sensor-529',\n",
       " 'Sensor-530',\n",
       " 'Sensor-531',\n",
       " 'Sensor-532',\n",
       " 'Sensor-533',\n",
       " 'Sensor-534',\n",
       " 'Sensor-535',\n",
       " 'Sensor-536',\n",
       " 'Sensor-537',\n",
       " 'Sensor-538',\n",
       " 'Sensor-539',\n",
       " 'Sensor-582',\n",
       " 'Sensor-590']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(list1,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-4</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-8</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-582</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>Sensor-590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1517.0152</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>64.240500</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>64.2405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>1397.5060</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>81.250167</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>1236.5212</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>44.249467</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1302.6607</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>84.270400</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3069.0</td>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1425.1041</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>31.377100</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>3070.0</td>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1202.4520</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>81.147333</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>2.3590</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>31.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3071.0</td>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1657.3518</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>109.599600</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3072.0</td>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1351.9648</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>106.370067</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3073.0</td>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1448.8499</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>69.267033</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>109.5996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Sensor-1  Sensor-2   Sensor-3   Sensor-4  Sensor-5  \\\n",
       "0            0.0   3076.81   2158.75  2208.2334  1517.0152    1.0980   \n",
       "1            1.0   2951.62   2511.92  2253.5111  1397.5060    0.9660   \n",
       "2            2.0   2930.42   2505.17  2235.0556  1302.6607    1.6347   \n",
       "3            3.0   2997.28   2357.99  2141.0667  1236.5212    0.9698   \n",
       "4            4.0   3025.10   2475.18  2235.0556  1302.6607    1.6347   \n",
       "...          ...       ...       ...        ...        ...       ...   \n",
       "3069      3069.0   3079.17   2405.56  2217.3777  1425.1041    1.7585   \n",
       "3070      3070.0   2911.37   2541.21  2207.8111  1202.4520    1.6219   \n",
       "3071      3071.0   3085.57   2364.78  2178.6889  1657.3518    1.6603   \n",
       "3072      3072.0   3053.49   2457.08  2172.5333  1351.9648    1.6377   \n",
       "3073      3073.0   3120.68   2396.40  2177.0222  1448.8499    1.5565   \n",
       "\n",
       "      Sensor-6  Sensor-7  Sensor-8  Sensor-9  ...  Sensor-581  Sensor-582  \\\n",
       "0        100.0  110.1900    0.1247    1.4357  ...    0.009000   64.240500   \n",
       "1        100.0  109.7611    0.1210    1.5527  ...    0.008100    0.000000   \n",
       "2        100.0  109.9856    0.1230    1.4588  ...    0.007333   81.250167   \n",
       "3        100.0   98.3344    0.1238    1.5973  ...    0.004733   44.249467   \n",
       "4        100.0  109.9856    0.1230    1.5525  ...    0.005867   84.270400   \n",
       "...        ...       ...       ...       ...  ...         ...         ...   \n",
       "3069     100.0  106.2556    0.1200    1.4794  ...    0.002400   31.377100   \n",
       "3070     100.0  108.7689    0.1212    1.5322  ...    0.005200   81.147333   \n",
       "3071     100.0  100.8022    0.1229    1.4945  ...    0.004400  109.599600   \n",
       "3072     100.0  103.8800    0.1243    1.5680  ...    0.006233  106.370067   \n",
       "3073     100.0  103.2567    0.1232    1.4920  ...    0.005333   69.267033   \n",
       "\n",
       "      Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  \\\n",
       "0         0.5016    0.015200    0.004000      3.0319      0.0465      0.0299   \n",
       "1         0.4953    0.010500    0.003700      2.1266     -0.0012      0.0252   \n",
       "2         0.4958    0.011100    0.003300      2.2296     -0.0012      0.0252   \n",
       "3         0.4962    0.008600    0.002400      1.7297     -0.0012      0.0252   \n",
       "4         0.4983    0.015900    0.004100      3.1927     -0.0012      0.0252   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069      0.5080    0.013900    0.003900      2.7328      0.0234      0.0073   \n",
       "3070      0.5026    0.011867    0.003133      2.3590      0.0234      0.0073   \n",
       "3071      0.4986    0.014700    0.003800      2.9493      0.0142      0.0156   \n",
       "3072      0.4981    0.013200    0.003500      2.6491      0.0142      0.0156   \n",
       "3073      0.4975    0.014000    0.003600      2.8098      0.0142      0.0156   \n",
       "\n",
       "      Sensor-589  Sensor-590  \n",
       "0         0.0090     64.2405  \n",
       "1         0.0081      0.0000  \n",
       "2         0.0081      0.0000  \n",
       "3         0.0081      0.0000  \n",
       "4         0.0081      0.0000  \n",
       "...          ...         ...  \n",
       "3069      0.0024     31.3771  \n",
       "3070      0.0024     31.3771  \n",
       "3071      0.0044    109.5996  \n",
       "3072      0.0044    109.5996  \n",
       "3073      0.0044    109.5996  \n",
       "\n",
       "[3074 rows x 591 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-579</th>\n",
       "      <th>Sensor-580</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028033</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027500</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>2.3590</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027567</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  403 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0      3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1      2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2      2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3      2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4      3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556    1.4794   \n",
       "3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689    1.5322   \n",
       "3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022    1.4945   \n",
       "3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800    1.5680   \n",
       "3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567    1.4920   \n",
       "\n",
       "      Sensor-10  Sensor-11  Sensor-12  ...  Sensor-579  Sensor-580  \\\n",
       "0        0.0089     0.0052     0.9655  ...    0.046500    0.029900   \n",
       "1        0.0119    -0.0082     0.9572  ...   -0.001200    0.025200   \n",
       "2       -0.0143     0.0017     0.9702  ...    0.027600    0.020000   \n",
       "3       -0.0534    -0.0284     0.9708  ...    0.028033    0.013267   \n",
       "4       -0.0078    -0.0005     0.9680  ...    0.027500    0.018433   \n",
       "...         ...        ...        ...  ...         ...         ...   \n",
       "3069    -0.0198    -0.0004     0.9535  ...    0.023400    0.007300   \n",
       "3070     0.0205    -0.0213     0.9561  ...    0.017967    0.013933   \n",
       "3071     0.0247    -0.0049     0.9560  ...    0.014200    0.015600   \n",
       "3072     0.0009     0.0094     0.9560  ...    0.027000    0.020033   \n",
       "3073    -0.0095     0.0165     0.9525  ...    0.027567    0.016700   \n",
       "\n",
       "      Sensor-581  Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  \\\n",
       "0       0.009000      0.5016    0.015200    0.004000      3.0319      0.0465   \n",
       "1       0.008100      0.4953    0.010500    0.003700      2.1266     -0.0012   \n",
       "2       0.007333      0.4958    0.011100    0.003300      2.2296     -0.0012   \n",
       "3       0.004733      0.4962    0.008600    0.002400      1.7297     -0.0012   \n",
       "4       0.005867      0.4983    0.015900    0.004100      3.1927     -0.0012   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069    0.002400      0.5080    0.013900    0.003900      2.7328      0.0234   \n",
       "3070    0.005200      0.5026    0.011867    0.003133      2.3590      0.0234   \n",
       "3071    0.004400      0.4986    0.014700    0.003800      2.9493      0.0142   \n",
       "3072    0.006233      0.4981    0.013200    0.003500      2.6491      0.0142   \n",
       "3073    0.005333      0.4975    0.014000    0.003600      2.8098      0.0142   \n",
       "\n",
       "      Sensor-588  Sensor-589  \n",
       "0         0.0299      0.0090  \n",
       "1         0.0252      0.0081  \n",
       "2         0.0252      0.0081  \n",
       "3         0.0252      0.0081  \n",
       "4         0.0252      0.0081  \n",
       "...          ...         ...  \n",
       "3069      0.0073      0.0024  \n",
       "3070      0.0073      0.0024  \n",
       "3071      0.0156      0.0044  \n",
       "3072      0.0156      0.0044  \n",
       "3073      0.0156      0.0044  \n",
       "\n",
       "[3074 rows x 403 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusternumbers=cluster_model.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['cluster']=clusternumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-580</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013267</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018433</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013933</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>2.3590</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020033</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0      3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1      2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2      2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3      2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4      3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556    1.4794   \n",
       "3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689    1.5322   \n",
       "3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022    1.4945   \n",
       "3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800    1.5680   \n",
       "3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567    1.4920   \n",
       "\n",
       "      Sensor-10  Sensor-11  Sensor-12  ...  Sensor-580  Sensor-581  \\\n",
       "0        0.0089     0.0052     0.9655  ...    0.029900    0.009000   \n",
       "1        0.0119    -0.0082     0.9572  ...    0.025200    0.008100   \n",
       "2       -0.0143     0.0017     0.9702  ...    0.020000    0.007333   \n",
       "3       -0.0534    -0.0284     0.9708  ...    0.013267    0.004733   \n",
       "4       -0.0078    -0.0005     0.9680  ...    0.018433    0.005867   \n",
       "...         ...        ...        ...  ...         ...         ...   \n",
       "3069    -0.0198    -0.0004     0.9535  ...    0.007300    0.002400   \n",
       "3070     0.0205    -0.0213     0.9561  ...    0.013933    0.005200   \n",
       "3071     0.0247    -0.0049     0.9560  ...    0.015600    0.004400   \n",
       "3072     0.0009     0.0094     0.9560  ...    0.020033    0.006233   \n",
       "3073    -0.0095     0.0165     0.9525  ...    0.016700    0.005333   \n",
       "\n",
       "      Sensor-583  Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  \\\n",
       "0         0.5016    0.015200    0.004000      3.0319      0.0465      0.0299   \n",
       "1         0.4953    0.010500    0.003700      2.1266     -0.0012      0.0252   \n",
       "2         0.4958    0.011100    0.003300      2.2296     -0.0012      0.0252   \n",
       "3         0.4962    0.008600    0.002400      1.7297     -0.0012      0.0252   \n",
       "4         0.4983    0.015900    0.004100      3.1927     -0.0012      0.0252   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069      0.5080    0.013900    0.003900      2.7328      0.0234      0.0073   \n",
       "3070      0.5026    0.011867    0.003133      2.3590      0.0234      0.0073   \n",
       "3071      0.4986    0.014700    0.003800      2.9493      0.0142      0.0156   \n",
       "3072      0.4981    0.013200    0.003500      2.6491      0.0142      0.0156   \n",
       "3073      0.4975    0.014000    0.003600      2.8098      0.0142      0.0156   \n",
       "\n",
       "      Sensor-589  cluster  \n",
       "0         0.0090        0  \n",
       "1         0.0081        0  \n",
       "2         0.0081        3  \n",
       "3         0.0081        0  \n",
       "4         0.0081        1  \n",
       "...          ...      ...  \n",
       "3069      0.0024        3  \n",
       "3070      0.0024        0  \n",
       "3071      0.0044        3  \n",
       "3072      0.0044        1  \n",
       "3073      0.0044        0  \n",
       "\n",
       "[3074 rows x 404 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-580</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.0</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "      <td>3074.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3014.848137</td>\n",
       "      <td>2495.503572</td>\n",
       "      <td>2200.503905</td>\n",
       "      <td>4.228111</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.055678</td>\n",
       "      <td>1.461944</td>\n",
       "      <td>-0.000812</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.964460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016963</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>0.500106</td>\n",
       "      <td>0.015027</td>\n",
       "      <td>0.003782</td>\n",
       "      <td>3.007204</td>\n",
       "      <td>0.021432</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>1.767404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73.870647</td>\n",
       "      <td>80.310713</td>\n",
       "      <td>29.396767</td>\n",
       "      <td>56.638244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.255938</td>\n",
       "      <td>0.074034</td>\n",
       "      <td>0.015015</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>2.640421</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>1.357230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2743.240000</td>\n",
       "      <td>2158.750000</td>\n",
       "      <td>2060.660000</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.131100</td>\n",
       "      <td>1.191000</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>-0.034900</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.197500</td>\n",
       "      <td>-0.016900</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2966.965000</td>\n",
       "      <td>2452.520000</td>\n",
       "      <td>2181.044400</td>\n",
       "      <td>1.017700</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.793350</td>\n",
       "      <td>1.410300</td>\n",
       "      <td>-0.010700</td>\n",
       "      <td>-0.005600</td>\n",
       "      <td>0.958100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>2.309900</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3011.840000</td>\n",
       "      <td>2498.910000</td>\n",
       "      <td>2201.066700</td>\n",
       "      <td>1.316800</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.492200</td>\n",
       "      <td>1.460900</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.965900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016267</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.757700</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3057.325000</td>\n",
       "      <td>2538.430000</td>\n",
       "      <td>2218.055500</td>\n",
       "      <td>1.529100</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.521100</td>\n",
       "      <td>1.516400</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.971500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.502375</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.295400</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3356.350000</td>\n",
       "      <td>2846.440000</td>\n",
       "      <td>2315.266700</td>\n",
       "      <td>1114.536600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>129.252200</td>\n",
       "      <td>1.656400</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.984800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>98.662800</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  404 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sensor-1     Sensor-2     Sensor-3     Sensor-5  Sensor-6  \\\n",
       "count  3074.000000  3074.000000  3074.000000  3074.000000    3074.0   \n",
       "mean   3014.848137  2495.503572  2200.503905     4.228111     100.0   \n",
       "std      73.870647    80.310713    29.396767    56.638244       0.0   \n",
       "min    2743.240000  2158.750000  2060.660000     0.681500     100.0   \n",
       "25%    2966.965000  2452.520000  2181.044400     1.017700     100.0   \n",
       "50%    3011.840000  2498.910000  2201.066700     1.316800     100.0   \n",
       "75%    3057.325000  2538.430000  2218.055500     1.529100     100.0   \n",
       "max    3356.350000  2846.440000  2315.266700  1114.536600     100.0   \n",
       "\n",
       "          Sensor-7     Sensor-9    Sensor-10    Sensor-11    Sensor-12  ...  \\\n",
       "count  3074.000000  3074.000000  3074.000000  3074.000000  3074.000000  ...   \n",
       "mean    101.055678     1.461944    -0.000812     0.000110     0.964460  ...   \n",
       "std       6.255938     0.074034     0.015015     0.009287     0.012483  ...   \n",
       "min      82.131100     1.191000    -0.053400    -0.034900     0.655400  ...   \n",
       "25%      97.793350     1.410300    -0.010700    -0.005600     0.958100  ...   \n",
       "50%     101.492200     1.460900    -0.001300     0.000400     0.965900  ...   \n",
       "75%     104.521100     1.516400     0.008300     0.005900     0.971500  ...   \n",
       "max     129.252200     1.656400     0.074900     0.053000     0.984800  ...   \n",
       "\n",
       "        Sensor-580   Sensor-581   Sensor-583   Sensor-584   Sensor-585  \\\n",
       "count  3074.000000  3074.000000  3074.000000  3074.000000  3074.000000   \n",
       "mean      0.016963     0.005439     0.500106     0.015027     0.003782   \n",
       "std       0.006883     0.002255     0.003356     0.012694     0.002732   \n",
       "min       0.003200     0.001000     0.477800     0.006000     0.001700   \n",
       "25%       0.013175     0.004200     0.497900     0.011600     0.003100   \n",
       "50%       0.016267     0.005200     0.500200     0.013800     0.003600   \n",
       "75%       0.019100     0.006133     0.502375     0.016500     0.004100   \n",
       "max       0.079900     0.028600     0.509800     0.471400     0.103900   \n",
       "\n",
       "        Sensor-586   Sensor-587   Sensor-588   Sensor-589      cluster  \n",
       "count  3074.000000  3074.000000  3074.000000  3074.000000  3074.000000  \n",
       "mean      3.007204     0.021432     0.016414     0.005268     1.767404  \n",
       "std       2.640421     0.012396     0.008767     0.002864     1.357230  \n",
       "min       1.197500    -0.016900     0.003200     0.001000     0.000000  \n",
       "25%       2.309900     0.013400     0.010600     0.003300     0.000000  \n",
       "50%       2.757700     0.020700     0.014800     0.004600     3.000000  \n",
       "75%       3.295400     0.027600     0.020300     0.006400     3.000000  \n",
       "max      98.662800     0.102800     0.079900     0.028600     3.000000  \n",
       "\n",
       "[8 rows x 404 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sensor-1      2743.2400\n",
       "Sensor-2      2158.7500\n",
       "Sensor-3      2060.6600\n",
       "Sensor-5         0.6815\n",
       "Sensor-6       100.0000\n",
       "                ...    \n",
       "Sensor-586       1.1975\n",
       "Sensor-587      -0.0169\n",
       "Sensor-588       0.0032\n",
       "Sensor-589       0.0010\n",
       "cluster          0.0000\n",
       "Name: min, Length: 404, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Wafer']=wafer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "er=df2['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in er:\n",
    "    dataframe1=df2[df2['cluster']==i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sensor-1</th>\n",
       "      <th>Sensor-2</th>\n",
       "      <th>Sensor-3</th>\n",
       "      <th>Sensor-5</th>\n",
       "      <th>Sensor-6</th>\n",
       "      <th>Sensor-7</th>\n",
       "      <th>Sensor-9</th>\n",
       "      <th>Sensor-10</th>\n",
       "      <th>Sensor-11</th>\n",
       "      <th>Sensor-12</th>\n",
       "      <th>...</th>\n",
       "      <th>Sensor-581</th>\n",
       "      <th>Sensor-583</th>\n",
       "      <th>Sensor-584</th>\n",
       "      <th>Sensor-585</th>\n",
       "      <th>Sensor-586</th>\n",
       "      <th>Sensor-587</th>\n",
       "      <th>Sensor-588</th>\n",
       "      <th>Sensor-589</th>\n",
       "      <th>cluster</th>\n",
       "      <th>Wafer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3076.81</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2208.2334</td>\n",
       "      <td>1.0980</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.1900</td>\n",
       "      <td>1.4357</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>3.0319</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2951.62</td>\n",
       "      <td>2511.92</td>\n",
       "      <td>2253.5111</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.7611</td>\n",
       "      <td>1.5527</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>-0.0082</td>\n",
       "      <td>0.9572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2930.42</td>\n",
       "      <td>2505.17</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.4588</td>\n",
       "      <td>-0.0143</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.2296</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>3</td>\n",
       "      <td>Wafer-503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2997.28</td>\n",
       "      <td>2357.99</td>\n",
       "      <td>2141.0667</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.3344</td>\n",
       "      <td>1.5973</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0284</td>\n",
       "      <td>0.9708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>1.7297</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025.10</td>\n",
       "      <td>2475.18</td>\n",
       "      <td>2235.0556</td>\n",
       "      <td>1.6347</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.9856</td>\n",
       "      <td>1.5525</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.4983</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.1927</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>1</td>\n",
       "      <td>Wafer-505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3079.17</td>\n",
       "      <td>2405.56</td>\n",
       "      <td>2217.3777</td>\n",
       "      <td>1.7585</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.2556</td>\n",
       "      <td>1.4794</td>\n",
       "      <td>-0.0198</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2.7328</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>3</td>\n",
       "      <td>Wafer-396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>2911.37</td>\n",
       "      <td>2541.21</td>\n",
       "      <td>2207.8111</td>\n",
       "      <td>1.6219</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.7689</td>\n",
       "      <td>1.5322</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>2.3590</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>3085.57</td>\n",
       "      <td>2364.78</td>\n",
       "      <td>2178.6889</td>\n",
       "      <td>1.6603</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.8022</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>-0.0049</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.4986</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>3</td>\n",
       "      <td>Wafer-398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>3053.49</td>\n",
       "      <td>2457.08</td>\n",
       "      <td>2172.5333</td>\n",
       "      <td>1.6377</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.8800</td>\n",
       "      <td>1.5680</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.4981</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.6491</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "      <td>Wafer-399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>3120.68</td>\n",
       "      <td>2396.40</td>\n",
       "      <td>2177.0222</td>\n",
       "      <td>1.5565</td>\n",
       "      <td>100.0</td>\n",
       "      <td>103.2567</td>\n",
       "      <td>1.4920</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.8098</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0</td>\n",
       "      <td>Wafer-400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3074 rows  405 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sensor-1  Sensor-2   Sensor-3  Sensor-5  Sensor-6  Sensor-7  Sensor-9  \\\n",
       "0      3076.81   2158.75  2208.2334    1.0980     100.0  110.1900    1.4357   \n",
       "1      2951.62   2511.92  2253.5111    0.9660     100.0  109.7611    1.5527   \n",
       "2      2930.42   2505.17  2235.0556    1.6347     100.0  109.9856    1.4588   \n",
       "3      2997.28   2357.99  2141.0667    0.9698     100.0   98.3344    1.5973   \n",
       "4      3025.10   2475.18  2235.0556    1.6347     100.0  109.9856    1.5525   \n",
       "...        ...       ...        ...       ...       ...       ...       ...   \n",
       "3069   3079.17   2405.56  2217.3777    1.7585     100.0  106.2556    1.4794   \n",
       "3070   2911.37   2541.21  2207.8111    1.6219     100.0  108.7689    1.5322   \n",
       "3071   3085.57   2364.78  2178.6889    1.6603     100.0  100.8022    1.4945   \n",
       "3072   3053.49   2457.08  2172.5333    1.6377     100.0  103.8800    1.5680   \n",
       "3073   3120.68   2396.40  2177.0222    1.5565     100.0  103.2567    1.4920   \n",
       "\n",
       "      Sensor-10  Sensor-11  Sensor-12  ...  Sensor-581  Sensor-583  \\\n",
       "0        0.0089     0.0052     0.9655  ...    0.009000      0.5016   \n",
       "1        0.0119    -0.0082     0.9572  ...    0.008100      0.4953   \n",
       "2       -0.0143     0.0017     0.9702  ...    0.007333      0.4958   \n",
       "3       -0.0534    -0.0284     0.9708  ...    0.004733      0.4962   \n",
       "4       -0.0078    -0.0005     0.9680  ...    0.005867      0.4983   \n",
       "...         ...        ...        ...  ...         ...         ...   \n",
       "3069    -0.0198    -0.0004     0.9535  ...    0.002400      0.5080   \n",
       "3070     0.0205    -0.0213     0.9561  ...    0.005200      0.5026   \n",
       "3071     0.0247    -0.0049     0.9560  ...    0.004400      0.4986   \n",
       "3072     0.0009     0.0094     0.9560  ...    0.006233      0.4981   \n",
       "3073    -0.0095     0.0165     0.9525  ...    0.005333      0.4975   \n",
       "\n",
       "      Sensor-584  Sensor-585  Sensor-586  Sensor-587  Sensor-588  Sensor-589  \\\n",
       "0       0.015200    0.004000      3.0319      0.0465      0.0299      0.0090   \n",
       "1       0.010500    0.003700      2.1266     -0.0012      0.0252      0.0081   \n",
       "2       0.011100    0.003300      2.2296     -0.0012      0.0252      0.0081   \n",
       "3       0.008600    0.002400      1.7297     -0.0012      0.0252      0.0081   \n",
       "4       0.015900    0.004100      3.1927     -0.0012      0.0252      0.0081   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3069    0.013900    0.003900      2.7328      0.0234      0.0073      0.0024   \n",
       "3070    0.011867    0.003133      2.3590      0.0234      0.0073      0.0024   \n",
       "3071    0.014700    0.003800      2.9493      0.0142      0.0156      0.0044   \n",
       "3072    0.013200    0.003500      2.6491      0.0142      0.0156      0.0044   \n",
       "3073    0.014000    0.003600      2.8098      0.0142      0.0156      0.0044   \n",
       "\n",
       "      cluster      Wafer  \n",
       "0           0  Wafer-501  \n",
       "1           0  Wafer-502  \n",
       "2           3  Wafer-503  \n",
       "3           0  Wafer-504  \n",
       "4           1  Wafer-505  \n",
       "...       ...        ...  \n",
       "3069        3  Wafer-396  \n",
       "3070        0  Wafer-397  \n",
       "3071        3  Wafer-398  \n",
       "3072        1  Wafer-399  \n",
       "3073        0  Wafer-400  \n",
       "\n",
       "[3074 rows x 405 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "c:\\Users\\rajes\\wafer_detection\\wafer\\lib\\site-packages\\pandas\\core\\frame.py:4174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "for i in er:\n",
    "    dataframe1=df2[df2['cluster']==i]\n",
    "    wafer=dataframe1['Wafer']\n",
    "    dataframe1.drop(['cluster','Wafer'],axis=1,inplace=True)\n",
    "    modelname=pickle.load(open(f'C:/Users/rajes/wafer_detection/data_training/xgboost_{i+1}.pkl','rb'))\n",
    "    predict_values=modelname.predict(dataframe1)\n",
    "    list1=[]\n",
    "    for i in wafer:\n",
    "        list1.append([i])\n",
    "    for i in range(len(predict_values)):\n",
    "        list1[i].append(predict_values[i])    \n",
    "    with open('predictions.txt','a') as file:\n",
    "        file.write(str(list1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "index1=wafer.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    3,    7,    9,   14,   15,   16,   17,   20,\n",
       "            ...\n",
       "            3052, 3053, 3054, 3056, 3060, 3063, 3064, 3066, 3070, 3073],\n",
       "           dtype='int64', length=969)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
